{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction to the docs\n\n\nThanks for visiting! This documentation is for \nOpenFn.org\n, and is primarily intended to help users of the site. Technical documentation for OpenFn's open-source integration tools and language-packs can be found in their respective repositories at \nGithub.com/OpenFn\n.\n\n\nWe've broken the documentation into three parts: an introduction, detailed documentation, and release notes.\n\n\nIf you want a new feature or find a bug, please \nsubmit an issue\n. If you find an issue with the documentation or want to share your custom functions, please \nsubmit a pull request\n!\n\n\n\n\nWait, so, OpenFn does what now?\n\n\n\n\nGood question:\n\n\n\n\n\n\nA source application sends \nmessages\n to your project\u2019s \ninbox\n when something happens.\n\n\n\n\n\n\nJobs\n will be triggered, based on your \nfilters\n, and use the data in those messages to attempt specific actions in destination systems.\n\n\n\n\n\n\nThe \nlogs\n are recorded so you can see precisely what happened and when and where it happened to take action in the event of a failed attempt\u2014like editing the job or even the source message and trying it again.\n\n\n\n\n\n\nOpenFn has harnessed the extreme  stability and scalability of Erlang to coordinate these actions and provide users with email alerts, project management tools, and an online job writing IDE.\n\n\nIn this guide you'll find documentation to help you write filters and jobs, along with explanations of OpenFn's key concepts.\n\n\nIf you have any questions, please don't hesitate to email \nadmin@openfn.org\n.\n\n\nQuick-start guide\n\n\nWant to get up and running with OpenFn in a few minutes? Follow these steps to set up your project and see the power of OpenFn in action!\n\n\n1. Create your account.\n If you haven't already, create an account at \nOpenFn.org\n\n\n2. Log In.\n After logging into your new account, you will see an overview of your current projects and the job runs associated with that project. This is called the outer \nDashboard\n. Click on one to start.\n\n\n3. Check your inbox.\n You should now be looking at the OpenFn User dashboard for a particular project, made up of the following navigation tabs:\n\n\n\n\nJobs\n\n\nTriggers\n\n\nCredentials\n\n\nInbox\n\n\nActivity\n\n\nSettings\n\n\n\n\nClick on the Inbox tab.\n\n\n4. Run a job.\n You should see your first message associated with a \"sample job\". Click on it. You can now choose to do the following:\n\n\n\n\nEdit the message (mainly for the purpose of fixing mistakes in data),\n\n\nManually run the job associated with a filter which has identified your first message as a trigger.\n\n\n\n\nClick run.\n\n\n5. View the logs.\n Wait for the job to finish and then click on \"View Logs\" to see what happened to the data inside of the message. You can view every job run from the \"Activity\" tab.\n\n\n6. Familiarize yourself with the other tabs.\n\n\nNavigate to \nTriggers\n. You can see that the sample filter we provided you required a message to be sent from OpenFn in order to trigger a job run. Click on the filter to edit it. Click save when you are done.\n\n\nNavigate to \nJobs\n. Here you can:\n\n\n\n\nYou can click to view the job that was run when triggered by the sample filter and sample message.\n\n\nClick on \"Edit Job\" to edit the .js file which executes a specific action (job).\n\n\nClick on the specified filter to change which filter should trigger that job.\n\n\n\n\nNavigate to \nCredentials\n to edit the destination system you want to connect to. By default, we have provided credentials to access the Salesforce sandbox environment.\n\n\nNavigate to the \nSettings\n tab to change the project's name, upgrade your account for more jobs and runs, add collaborators, and transfer project ownership.", 
            "title": "Home"
        }, 
        {
            "location": "/#introduction-to-the-docs", 
            "text": "Thanks for visiting! This documentation is for  OpenFn.org , and is primarily intended to help users of the site. Technical documentation for OpenFn's open-source integration tools and language-packs can be found in their respective repositories at  Github.com/OpenFn .  We've broken the documentation into three parts: an introduction, detailed documentation, and release notes.  If you want a new feature or find a bug, please  submit an issue . If you find an issue with the documentation or want to share your custom functions, please  submit a pull request !   Wait, so, OpenFn does what now?   Good question:    A source application sends  messages  to your project\u2019s  inbox  when something happens.    Jobs  will be triggered, based on your  filters , and use the data in those messages to attempt specific actions in destination systems.    The  logs  are recorded so you can see precisely what happened and when and where it happened to take action in the event of a failed attempt\u2014like editing the job or even the source message and trying it again.    OpenFn has harnessed the extreme  stability and scalability of Erlang to coordinate these actions and provide users with email alerts, project management tools, and an online job writing IDE.  In this guide you'll find documentation to help you write filters and jobs, along with explanations of OpenFn's key concepts.  If you have any questions, please don't hesitate to email  admin@openfn.org .", 
            "title": "Introduction to the docs"
        }, 
        {
            "location": "/#quick-start-guide", 
            "text": "Want to get up and running with OpenFn in a few minutes? Follow these steps to set up your project and see the power of OpenFn in action!  1. Create your account.  If you haven't already, create an account at  OpenFn.org  2. Log In.  After logging into your new account, you will see an overview of your current projects and the job runs associated with that project. This is called the outer  Dashboard . Click on one to start.  3. Check your inbox.  You should now be looking at the OpenFn User dashboard for a particular project, made up of the following navigation tabs:   Jobs  Triggers  Credentials  Inbox  Activity  Settings   Click on the Inbox tab.  4. Run a job.  You should see your first message associated with a \"sample job\". Click on it. You can now choose to do the following:   Edit the message (mainly for the purpose of fixing mistakes in data),  Manually run the job associated with a filter which has identified your first message as a trigger.   Click run.  5. View the logs.  Wait for the job to finish and then click on \"View Logs\" to see what happened to the data inside of the message. You can view every job run from the \"Activity\" tab.  6. Familiarize yourself with the other tabs.  Navigate to  Triggers . You can see that the sample filter we provided you required a message to be sent from OpenFn in order to trigger a job run. Click on the filter to edit it. Click save when you are done.  Navigate to  Jobs . Here you can:   You can click to view the job that was run when triggered by the sample filter and sample message.  Click on \"Edit Job\" to edit the .js file which executes a specific action (job).  Click on the specified filter to change which filter should trigger that job.   Navigate to  Credentials  to edit the destination system you want to connect to. By default, we have provided credentials to access the Salesforce sandbox environment.  Navigate to the  Settings  tab to change the project's name, upgrade your account for more jobs and runs, add collaborators, and transfer project ownership.", 
            "title": "Quick-start guide"
        }, 
        {
            "location": "/documentation/", 
            "text": "Connecting Source Applications\n\n\nMost modern web applications have a feature that allows you to \npush\n, \npublish\n, or \npost\n data to another URL when a certain \nevent\n takes place. This event could be a form submission, mobile payment, patient registration, or barcode scan submission from a mobile app. The key is that your source application will notify OpenFn when \nsomething happens\n.\n\n\n\n\n\n\nGo to the \"settings\" or \"administration\" page for your source app, and look for a \nWebhook API\n, \nData Forwarding API\n, or \nNotifications API\n. Write to the developers of your application if none is provided out of the box.\n\n\n\n\n\n\nWhen setting up forwarding, select to send messages in \nJSON\n to your project's \ninbox URL\n. You can find and copy your secure inbox URL by clicking on the \"copy URL\" link in the bottom-right corner of the project in question on your \nproject dashboard\n page.\n\n\n\n\n\n\nSoon you'll see new messages arrive in your \nhistory\n page.\n\n\n\n\n\n\nTriggers\n\n\nTriggers run jobs. They can either be \"filter\" triggers or \"timer\" triggers. Filter triggers watch incoming messages and run them through jobs when they match the filter criteria. Timer triggers run jobs after a recurring interval has elapsed.\n\n\nYou, as a user, specify the filter \ncriteria\n which determines which messages in your inbox should trigger job runs. This means that if any segment of a message body \nmatches\n the string of \nJSON\n you gave as a filter, the filter will run and trigger a job (assuming you created one).\n\n\nThe filter criteria takes the form of a string of valid \nJSON\n. In a SQL query, this string will be used in the WHERE clause, for example:\n\n\nSELECT * FROM receipts\n  WHERE body::jsonb @\n\n    '{\nName\n:\nAlex Iwobi\n}'::jsonb;\n\n\n\n\nFilter Matching\n\n\nTo illustrate filter matching, refer to the \nJSON\n strings below. Message \"a\" will match filter '1', but message \"b\" will not.\n\n\nfilter 1:\n\n\n{\nformID\n:\npatient_registration_v7\n}\n\n\n\n\nmessage a (MATCH):\n\n\n{\nsubmissionDate\n:\n2016-01-15\n, \nformID\n:\npatient_registration_v7\n, \nname\n:\nJack Wilshere\n, \ndob\n:\n1986-05-16\n, \nmedications\n: [\nanaphlene\n,\nzaradood\n,\nmorphofast\n]}\n\n\n\n\nmessage b (NO MATCH):\n\n\n{\nsubmissionDate\n:\n2016-01-16\n, \nformID\n:\npatient_registration_v8\n, \nname\n:\nLarry Bird\n, \ndob\n:\n1982-03-21\n, \nmedications\n: [\nanaphlene\n,\nzaradood\n,\nmorphofast\n]}\n\n\n\n\nMessage 'b' does not include \n\"formID\":\"patient_registration_v7\"\n and will not match filter '1'.\n\n\nCredentials\n\n\nCredentials are used to authorize connections to destination systems. In the future, our adaptors will use credentials to fetch meta-data from source and destination applications and make the job writing process easier.\n\n\nSome systems (Salesforce, OpenMRS, DHIS2) require an instanceUrl, host, or ApiUrl. Leave off the final \"/\" in these Urls:\n\nhttps://login.salesforce.com\n or \nhttp://demo.openmrs.org/openmrs\n or \nhttps://play.dhis2.org\n.\n\n\nCredentials can only be viewed, or edited by a single user \u2014 their \"owner\" (or the person that created that credential). All the collaborators on a particular project can choose those credentials for use when defining a job.\n\n\nJobs\n\n\nA job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed.\n\n\nComposing Job Expressions\n\n\nIn most cases, a job expression is a series of \ncreate\n or \nupsert\n actions that are run after a message arrives, using data from that message. It could look like this:\n\n\ncreate(\nPatient__c\n, fields(\n  field(\nName\n, dataValue(\nform.surname\n)),\n  field(\nAge__c\n, 7)\n))\n\n\n\n\nThat would create a new \nPatient__c\n in some other system. The patient's \nName\n will be determined by the triggering message (the value inside \nform.name\n, specifically) and the patient's \nAge__c\n will \nalways\n be 7. See how we hard coded it?\n\n\nWhat you see above is OpenFn's own syntax, and you've got access to dozens of common \"helper functions\" like \ndataValue(path)\n and destination specific functions like \ncreate(object,attributes)\n. While most cases are covered out-of-the-box, jobs are \nevaluated as Javascript\n. This means that you can write your own custom, anonymous functions to do whatever your heart desires:\n\n\ncreate(\nPatient__c\n, fields(\n  field(\nName\n, function(state) {\n    return Array.apply(\n      null, dataValue(\npatient_names\n)(state)\n    ).join(', ')\n  })\n  field(\nAge__c\n, 7)\n\n\n\n\nHere, the patient's name will be a comma separated concatenation of all the values in the \npatient_names\n array from our source message.\n\n\nOther than the expression tree, Jobs have certain attributes that must be set:\n\n\n\n\nFilter\n - The message filter that will triggers the job.\n\n\nAdaptor\n - The adaptor for the destination system you're connecting to.\n\n\nCredential\n - The credential that will be used to gain access to that destination system.\n\n\nActive?\n - A boolean which determines whether the job runs in real-time when matching messages arrive.\n\n\n\n\nSelected Named Functions\n\n\nThere are lots more available in the language-packs.\n\n\nlanguage-common\n\n\n\n\nfield('destination_field_name__c', 'value')\n Returns a key, value pair in an array. \n(source)\n\n\nfields(list_of_fields)\n zips key value pairs into an object. \n(source)\n\n\ndataValue('JSON_path')\n Picks out a single value from source data. \n(source)\n\n\neach(JSON_path, operation(...))\n Scopes an array of data based on a JSONPath \n(source)\n\n\nbeta.each(JSON_path, operation(...))\n Pre-release: new feature details coming. \n(source)\n\n\neach(merge(dataPath(\"CHILD_ARRAY[*]\"),fields(field(\"metaId\", dataValue(\"*meta-instance-id*\")),field(\"parentId\", lastReferenceValue(\"id\")))), create(...))\n merges data into an array then creates for each item in the array \n(source)\n\n\nlastReferenceValue('id')\n gets the sfID of the last item created \n(source)\n\n\nfunction(state){return state.references[state.references.length-N].id})\n gets the sfID of the nth item created\n\n\n\n\nSalesforce\n\n\n\n\ncreate(\"DEST_OBJECT_NAME__C\", fields(...))\n Create a new object. Takes 2 parameters: An object and attributes. \n(source)\n\n\nupsert(\"DEST_OBJECT_NAME__C\", \"DEST_OBJECT_EXTERNAL_ID__C\", fields(...))\n Creates or updates an object. Takes 3 paraneters: An object, an ID field and attributes. \n(source)\n\n\nrelationship(\"DEST_RELATIONSHIP_NAME__r\", \"EXTERNAL_ID_ON_RELATED_OBJECT__C\", \"SOURCE_DATA_OR_VALUE\")\n Adds a lookup or 'dome insert' to a record. \n(source)\n\n\n\n\ndhis2\n\n\n\n\nevent(...)\n Creates an event. \n(source)\n\n\ndataValueSet(...)\n Send data values using the dataValueSets resource \n(source)\n\n\n\n\nOpenMRS\n\n\n\n\nperson(...)\n Takes a payload of data to create a person \n(source)\n\n\npatient(...)\n Takes a payload of data to create a patient \n(source)\n\n\n\n\nFor code block examples of job expressions, go to the \nAppendix\n.\n\n\nInbox\n\n\nYour inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data that were sent via HTTP post to your inbox. They can be viewed in formatted JSON, edited, or manually processed (if they did not match a filter when they were originally delivered.)\n\n\nTo edit a message, click the \"pencil and paper\" icon next to that receipt. Be careful, as no original copy will be persisted.\n\n\nActivity\n\n\nIn this section of the portal, you can view a list of all \"runs\" - i.e. individual job runs. This list is essentially a compilation of all jobs, messages and credentials flowing through your OpenFn account towards your destination system(s).\n\n\nRuns\n\n\nRuns are attempts made on a destination system by running a receipt through a Job Description. Runs can be viewed and re-processed. Each submission has a \nsuccess\n, \nstarted_at\n, \nfinsihed_at\n, \njob_description_id\n, and \nreceipt_id\n attribute. \nStarted_at\n and \nfinished_at\n are the timestamps when the submission began and ended.\n\n\n\n\nNote:\n Some runs may take a really long time, particularly if they are performing multiple actions in a destination system or if they are fetching lots of data from a REST api at the start of a migration. They will appear as red if they have failed. In the case of failure, refer to our \nTroubleshooting\n section below.\n\n\n\n\nTroubleshooting\n\n\n\n\nWhat happens if my survey data from ODK needs to link to existing records in my Salesforce system but a respondent enters or selects an invalid \nexternal ID\n?\n\n\n\n\nGreat question, and don't worry, it happens all the time. Assuming you've already taken all possible measures to either pre-load external IDs in your ODK form or use more human-proof IDs (like barcodes and fingerprints) here's the flow of work:\n\n\n\n\n\n\nRead the email, and inspect the reason for failure.\n\n\n\n\n\n\n99% of failed runs on OpenFn are due to \nvalue mismatches\n. The \ncollected\n \nid\n in ODK doesn't match the \nexpected\n \nid\n in Salesforce. You must now chose to either:\n\n\nA. Edit the source \nid\n in your \nreceipt\n \n retry the attempt.\n\n\nB. Edit the related \nid\n in your destination system \n retry the attempt.\n\n\nC. Ignore the attempt\u2014this source data will never reach your destination system. (There have been reports of ODK Aggregate's JSON publisher sending dupliate values. If that happens and your run fails due to \"duplicate values\" on a particular unique field you can safely ignore the run in OpenFn.)\n\n\n\n\n\n\nEditing data in your destination system can be done through that system's interface. Many tools that act as \nsources\n (like ODK) do not allow for easy editing and re-submission of data. You can use OpenFn to edit the source data before retrying the attempt.\n\n\nCommon Error Messages\n\n\nThe most common error messages with English explanations are:\n+ \nDUPLICATE_VALUE: duplicate value found: ODK_uuid__c duplicates value on record with id: a0524000005wNw0\n - The insert is blocked because you are attempting to create a new record with a unique field with the same value as an existing record.\n+ \nRequired value missing\n\n+ \nExternalId not found\n\n\nDIY\n\n\nOpenFn's core ETL tools are all open-source, and here we will explain how those tools can be used to perform ETL operations from your command line. You can even take this further and wrap them together in your own hosted service!\n\n\n\n\nETL\n = Extracting, Transforming and Loading of data\n\n\n\n\nTo get started, follow these steps:\n\n  1. Create an empty directory somewhere on your local machine (e.g. call it \"OpenFn\")\n  2. Open up a terminal, cd into the new directory, and git clone the following:\n    - \ngit clone\n \nfn-lang\n\n    - \ngit clone\n \nlanguage-common\n\n    - \ngit clone\n \nlanguage-xxx\n (an adaptor of your choice, from github.com/OpenFn)\n\n\n#### fn-lang (diesl)\nfn-lang is a coordination tool that takes a job expression, a JSON payload, an adaptor, and a configuration file, and runs the \"TL\" part of \"ETL\" on command. It can be run from a command line, or built into a hosted web service.\n\n#### language-common\n`language-common` provides basic data manipulation functionality like `each`, `field`, and `toArray`.\n\n#### language-xxx\n`language-xxx` is a \"destination adaptor\" that knows how to connect to the system in question and provides system-specific operations, like `relationship` or `upsert`. Examples: `language-dhis2`, `language-salesforce`, `language-openmrs`.\n\n\n\n\n\ncd into 'fn-lang'\n\n\n\n\ntype into the terminal the following commands (in order):\n\n\n\n\nnpm install\n\n\nnpm link ../language-common\n\n\nnpm link ../language-xxx (Whatever adaptor you chose. For this demonstration we will use DHIS2)\n\n\n\n\n\n\n\n\nCreate a folder named \"tmp\" inside \"fn-lang\".\n\n\n\n\nInside \"tmp\", you need to create 3 files: \nconfig.json\n, \nexpression.js\n and \nmessage.json\n.\n\n\n\n\n\n\nClick \nHERE\n to get started by using some sample code for each of the 3 files.\n\n\n\n\n\n\nRun fn-lang from the command line with the following:\n\n\n\n\n~/fn-lang$ lib/cli.js execute -l dhis2 -e tmp/expression.js -c tmp/config.json -d tmp/message.json\n\n\nCommand Explained:\n Execute an expression (-e) and load on some data (-d) using a language-pack (-l) and a destination configuration file (-c).\n\n\n\n\nNote:\n Depending on which language-pack you have decided to use, you will need to change this command by replacing \"dhis2\" with the name of the language-pack you are using. E.g. \"openmrs\" or \"salesforce/FakeAdaptor\" (special case).\n\n\n\n\n\n\nCheck out the results of the posted data! Open up expression.js and message.json to manipulate the outcome and get a feel for how it works.\n\n\n\n\nAppendix\n\n\nSample code for DIY section\n\n\nBelow you can find sample code to fill the 3 files required to run fn-lang - \nmessage.json\n, \nexpression.js\n and \nconfig.json\n.\n\n\nmessage.json\n\n\n{\n  \nxform_ids\n: [],\n  \nversion\n: null,\n  \nuser_id\n: \nuser1\n,\n  \nserver_date_opened\n: null,\n  \nserver_date_modified\n: null,\n  \nproperties\n: {\n    \nprop_c\n: \n2013-05-18\n,\n    \nprop_b\n: \nFemale\n,\n    \nprop_a\n: 99,\n    \nowner_id\n: null,\n    \nexternal_id\n: null,\n    \ndate_opened\n: null,\n    \ndate\n: \n2013-05-17\n,\n    \ncase_type\n: \ncase_type\n,\n    \ncase_name\n: \nDemo\n\n  },\n  \nindices\n: {}\n}\n\n\n\n\nexpression.js\n\n\nevent(\n  fields(\n    field(\nprogram\n, \neBAyeGv0exc\n),\n    field(\norgUnit\n, \nDiszpKrYNg8\n),\n    field(\neventDate\n, dataValue(\nproperties.date\n)),\n    field(\nstatus\n, \nCOMPLETED\n),\n    field(\nstoredBy\n, \nadmin\n),\n    field(\ncoordinate\n, {\n      \nlatitude\n: \n59.8\n,\n      \nlongitude\n: \n10.9\n\n    }),\n    field(\ndataValues\n, function(state) {\n      return [\n        { \ndataElement\n: \nqrur9Dvnyt5\n, \nvalue\n: dataValue(\nproperties.prop_a\n)(state) },\n        { \ndataElement\n: \noZg33kd9taw\n, \nvalue\n: dataValue(\nproperties.prop_b\n)(state) },\n        { \ndataElement\n: \nmsodh3rEMJa\n, \nvalue\n: dataValue(\nproperties.prop_c\n)(state) }\n      ]\n    })\n  )\n)\n\n\n\n\nconfig.json\n\n\n{\n  \nusername\n: \nadmin\n,\n  \npassword\n: \ndistrict\n,\n  \napiUrl\n: \nhttps://play.dhis2.org/demo\n\n}\n\n\n\n\nMore example filters\n\n\nMatch messages \nWHERE\n the \nformId\n is \n\"Robot_Photo_21.04.2015\"\n:\n\n\n{\nformId\n:\nRobot_Photo_21.04.2015\n}\n\n\n\n\nMatch a message \nWHERE\n this \nAND\n that are both included:\n\n\n{\nformId\n:\nRobot_Photo_21.04.2015\n, \nsecret_number\n:8}\n\n\n\n\nMatch a message with two fragments inside an array called \ndata\n:\n\n\n(This is useful when gathering data via ODK)\n\n\n{\ndata\n:[{\noutlet_call\n:\nTRUE\n,\nnew_existing\n:\nExisting\n}]}\n\n\n\n\nMatch a message with a fragment inside another object called \nform\n:\n\n\n{\nform\n:{\n@xmlns\n:\nhttp://openrosa.org/formdesigner/F732194-3278-nota-ReAL-one\n}}\n\n\n\n\nMore example jobs\n\n\nBelow you can find some examples of block code for different functions and data handling contexts.\n\n\nJob expression (for CommCare to SF)\n\n\nThe following job expression will take a matching receipt and use data from that receipt to upsert a \nPatient__c\n record in Salesforce and create multiple new \nPatient_Visit__c\n (child to Patient) records.\n\n\nupsert(\nPatient__c\n, \nPatient_Id__c\n, fields(\n  field(\nPatient_Id__c\n, dataValue(\nform.patient_ID\n)),\n  relationship(\nNurse__r\n, \nNurse_ID_code__c\n, dataValue(\nform.staff_id\n)),\n  field(\nPhone_Number__c\n, dataValue(\nform.mobile_phone\n))\n)),\neach(\n  join(\n$.data.form.visits[*]\n, \n$.references[0].id\n, \nId\n),\n  create(\nVisit__c\n, fields(\n    field(\nPatient__c\n, dataValue(\nId\n)),\n    field(\nDate__c\n, dataValue(\ndate\n)),\n    field(\nReason__c\n, dataValue(\nwhy_did_they_see_doctor\n))\n  ))\n)\n\n\n\n\nAccessing the \"data array\" in Open Data Kit submissions\n\n\nNotice how we use \"each\" to get data from each item inside the \"data array\" in ODK.\n\n\neach(\n  \n$.data.data[*]\n,\n  create(\nODK_Submission__c\n, fields(\n    field(\nSite_School_ID_Number__c\n, dataValue(\nschool\n)),\n    field(\nDate_Completed__c\n, dataValue(\ndate\n)),\n    field(\ncomments__c\n, dataValue(\ncomments\n)),\n    field(\nODK_Key__c\n, dataValue(\n*meta-instance-id*\n))\n  ))\n)\n\n\n\n\nODK to Salesforce: create parent record with many children from parent data\n\n\nHere, the user brings \ntime_end\n and \nparentId\n onto the line items from the parent object.\n\n\neach(\n  dataPath(\ndata[*]\n),\n  combine(\n    create(\ntransaction__c\n, fields(\n      field(\nTransaction_Date__c\n, dataValue(\ntoday\n)),\n      relationship(\nPerson_Responsible__r\n, \nStaff_ID_Code__c\n, dataValue(\nperson_code\n)),\n      field(\nmetainstanceid__c\n, dataValue(\n*meta-instance-id*\n))\n    )),\n    each(\n      merge(dataPath(\nline_items[*]\n), fields(\n        field(\nend\n, dataValue(\ntime_end\n)),\n        field(\nparentId\n, lastReferenceValue(\nid\n))\n      )),\n      create(\nline_item__c\n, fields(\n        field(\ntransaction__c\n, dataValue(\nparentId\n)),\n        field(\nBarcode__c\n, dataValue(\nproduct_barcode\n)),\n        field(\nODK_Form_Completed__c\n, dataValue(\nend\n))\n      ))\n    )\n  )\n)\n\n\n\n\n\n\nNB - there was a known bug with the \ncombine\n function which has been resolved. \ncombine\n can be used to combine two operations into one and is commonly used to run multiple \ncreate\n's inside an \neach(path, operation)\n. The source code for combine can be found here: \nlanguage-common: combine\n\n\n\n\nCreate many child records WITHOUT a repeat group in ODK\n\n\nbeta.each(\n  \n$.data.data[*]\n,\n  upsert(\nOutlet__c\n, \nOutlet_Code__c\n, fields(\n    field(\nOutlet_Code__c\n, dataValue(\noutlet_code\n)),\n    field(\nLocation__Latitude__s\n, dataValue(\ngps:Latitude\n)),\n    field(\nLocation__Longitude__s\n, dataValue(\ngps:Longitude\n))\n  ))\n),\nbeta.each(\n    \n$.data.data[*]\n,\n    upsert(\nOutlet_Call__c\n, \nInvoice_Number__c\n, fields(\n      field(\nInvoice_Number__c\n, dataValue(\ninvoice_number\n)),\n      relationship(\nOutlet__r\n, \nOutlet_Code__c\n, dataValue(\noutlet_code\n)),\n      relationship(\nRecordType\n, \nname\n, \nNo Call Card\n),\n      field(\nTrip__c\n, \na0FN0000008jPue\n),\n      relationship(\nSales_Person__r\n, \nSales_Rep_Code__c\n, dataValue(\nsales_rep_code\n)),\n      field(\nDate__c\n, dataValue(\ndate\n)),\n      field(\nComments__c\n, dataValue(\ncomments\n))\n  ))\n)\n\n\n\n\nSalesforce: Set record type using 'relationship(...)'\n\n\ncreate(\ncustom_obj__c\n, fields(\n            relationship(\nRecordType\n, \nname\n, dataValue(\nsubmission_type\n),\n            field(\nname\n, dataValue(\nName\n))\n            )\n      ))\n\n\n\n\nSalesforce: Set record type using record Type ID\n\n\neach(\n  \n$.data.data[*]\n,\n  create(\nfancy_object__c\n, fields(\n    field(\nRecordTypeId\n, \n012110000008s19\n),\n    field(\nsite_size\n, dataValue(\nsize\n))\n  ))\n)\n\n\n\n\nTelerivet: Send SMS based on Salesforce workflow alert\n\n\nsend(\n  fields(\n    field(\nto_number\n, dataValue(\nEnvelope.Body.notifications.Notification.sObject.phone_number__c\n)),\n    field(\nmessage_type\n, \nsms\n),\n    field(\nroute_id\n, \n),\n    field(\ncontent\n, function(state) {\n      return (\n        \nHey there. Your name is \n.concat(\n          dataValue(\nEnvelope.Body.notifications.Notification.sObject.name__c\n)(state),\n          \n.\n\n        )\n      )\n    })\n  )\n)\n\n\n\n\nSample DHIS2 events API job:\n\n\nevent(\n  fields(\n    field(\nprogram\n, \neBAyeGv0exc\n),\n    field(\norgUnit\n, \nDiszpKrYNg8\n),\n    field(\neventDate\n, dataValue(\nproperties.date\n)),\n    field(\nstatus\n, \nCOMPLETED\n),\n    field(\nstoredBy\n, \nadmin\n),\n    field(\ncoordinate\n, {\n      \nlatitude\n: \n59.8\n,\n      \nlongitude\n: \n10.9\n\n    }),\n    field(\ndataValues\n, function(state) {\n      return [\n        { \ndataElement\n: \nqrur9Dvnyt5\n, \nvalue\n: dataValue(\nproperties.prop_a\n)(state) },\n        { \ndataElement\n: \noZg33kd9taw\n, \nvalue\n: dataValue(\nproperties.prop_b\n)(state) },\n        { \ndataElement\n: \nmsodh3rEMJa\n, \nvalue\n: dataValue(\nproperties.prop_c\n)(state) }\n      ]\n    })\n  )\n)\n\n\n\n\nSample DHIS2 data value sets API job:\n\n\ndataValueSet(\n  fields(\n    field(\ndataSet\n, \npBOMPrpg1QX\n),\n    field(\norgUnit\n, \nDiszpKrYNg8\n),\n    field(\nperiod\n, \n201401\n),\n    field(\ncompleteData\n, dataValue(\ndate\n)),\n    field(\ndataValues\n, function(state) {\n      return [\n        { \ndataElement\n: \nf7n9E0hX8qk\n, \nvalue\n: dataValue(\nprop_a\n)(state) },\n        { \ndataElement\n: \nIx2HsbDMLea\n, \nvalue\n: dataValue(\nprop_b\n)(state) },\n        { \ndataElement\n: \neY5ehpbEsB7\n, \nvalue\n: dataValue(\nprop_c\n)(state) }\n      ]\n    })\n  )\n)\n\n\n\n\nsample openMRS expression, creates a person and then a patient\n\n\nperson(\n  fields(\n    field(\ngender\n, \nF\n),\n    field(\nnames\n, function(state) {\n      return [{\n        \ngivenName\n: dataValue(\nform.first_name\n)(state),\n        \nfamilyName\n: dataValue(\nform.last_name\n)(state)\n      }]\n    })\n  )\n),\npatient(\n  fields(\n    field(\nperson\n, lastReferenceValue(\nuuid\n)),\n    field(\nidentifiers\n, function(state) {\n      return [{\n        \nidentifier\n: \n1234\n,\n        \nidentifierType\n: \n8d79403a-c2cc-11de-8d13-0010c6dffd0f\n,\n        \nlocation\n: \n8d6c993e-c2cc-11de-8d13-0010c6dffd0f\n,\n        \npreferred\n: true\n      }]\n    })\n  )\n)\n\n\n\n\nExamples of Anonymous Functions\n\n\nDifferent to \nNamed Functions\n, Anoynmous functions are generic pieces of javascript which you can write to suit your needs. Here are some examples of these custom functions:\n\n\nCustom replacer\n\n\nfield(\n  \ndestination__c\n,\n  function(state){\n    return dataValue(\npath_to_data\n)(state).toString().replace(\ncats\n,\ndogs\n)\n  }\n)\n\n\n\n\nThis will replace all \"cats\" with \"dogs\" in the string that lives at \npath_to_data\n.\n\n\n\n\nNOTE:\n The JavaScript \nreplace()\n function only replaces the first instance of whatever argument you specify.\nIf you're looking for a way to replace all instances, we suggest you use a regex like we did in the \nexample\n below.\n\n\n\n\nCustom arrayToString\n\n\nfield(\ntarget_specie_list__c\n, function(state) {\n  return Array.apply(\n    null, sourceValue(\n$.data.target_specie_list\n)(state)\n  ).join(', ')\n}),\n\n\n\n\nIt will take an array, and concatenate each item into a string with a \", \" separator.\n\n\nCustom concatenation\n\n\nfield(\nODK_Key__c\n, function (state) {\n  return (\n    dataValue(\nmetaId\n)(state).concat(\n      \n(\n, dataValue(\nindex\n)(state), \n)\n\n    )\n  )\n})\n\n\n\n\nThis will concatenate two values.\n\n\nCustom concatenation of null values\n\n\nThis will concatenate many values, even if one or more are null, writing them to a field called Main_Office_City_c.\n\n\n...\n  field(\nMain_Office_City__c\n, function(state) {\n    return arrayToString([\n      dataValue(\nMain_Office_City_a\n)(state) === null ? \n : dataValue(\nMain_Office_City_a\n)(state).toString().replace(/-/g, \n \n),\n      dataValue(\nMain_Office_City_b\n)(state) === null ? \n : dataValue(\nMain_Office_City_b\n)(state).toString().replace(/-/g, \n \n),\n      dataValue(\nMain_Office_City_c\n)(state) === null ? \n : dataValue(\nMain_Office_City_c\n)(state).toString().replace(/-/g, \n \n),\n      dataValue(\nMain_Office_City_d\n)(state) === null ? \n : dataValue(\nMain_Office_City_d\n)(state).toString().replace(/-/g, \n \n),\n    ].filter(Boolean), ',')\n  })\n\n\n\n\n\n\nNotice how this custom function makes use of the \nregex\n \n/-/g\n to ensure that all instances are accounted for (g = global search).\n\n\n\n\nCustom Nth reference ID\n\n\nIf you ever want to retrieve the FIRST object you created, or the SECOND, or the Nth, for that matter, a function like this will do the trick.\n\n\nfield(\nparent__c\n, function(state) {\n    return state.references[state.references.length-1].id\n  })\n\n\n\n\nSee how instead of taking the id of the \"last\" thing that was created in Salesforce, you're taking the id of the 1st thing, or 2nd thing if you replace \"length-1\" with \"length-2\".\n\n\nConvert date string to standard ISO date for Salesforce\n\n\nfield(\nPayment_Date__c\n, function(state) {\n  return new Date(dataValue(\npayment_date\n)(state)).toISOString()\n})\n\n\n\n\n\n\nNOTE\n: The output of this function will always be formatted according to GMT time-zone.", 
            "title": "Documentation"
        }, 
        {
            "location": "/documentation/#connecting-source-applications", 
            "text": "Most modern web applications have a feature that allows you to  push ,  publish , or  post  data to another URL when a certain  event  takes place. This event could be a form submission, mobile payment, patient registration, or barcode scan submission from a mobile app. The key is that your source application will notify OpenFn when  something happens .    Go to the \"settings\" or \"administration\" page for your source app, and look for a  Webhook API ,  Data Forwarding API , or  Notifications API . Write to the developers of your application if none is provided out of the box.    When setting up forwarding, select to send messages in  JSON  to your project's  inbox URL . You can find and copy your secure inbox URL by clicking on the \"copy URL\" link in the bottom-right corner of the project in question on your  project dashboard  page.    Soon you'll see new messages arrive in your  history  page.", 
            "title": "Connecting Source Applications"
        }, 
        {
            "location": "/documentation/#triggers", 
            "text": "Triggers run jobs. They can either be \"filter\" triggers or \"timer\" triggers. Filter triggers watch incoming messages and run them through jobs when they match the filter criteria. Timer triggers run jobs after a recurring interval has elapsed.  You, as a user, specify the filter  criteria  which determines which messages in your inbox should trigger job runs. This means that if any segment of a message body  matches  the string of  JSON  you gave as a filter, the filter will run and trigger a job (assuming you created one).  The filter criteria takes the form of a string of valid  JSON . In a SQL query, this string will be used in the WHERE clause, for example:  SELECT * FROM receipts\n  WHERE body::jsonb @ \n    '{ Name : Alex Iwobi }'::jsonb;", 
            "title": "Triggers"
        }, 
        {
            "location": "/documentation/#filter-matching", 
            "text": "To illustrate filter matching, refer to the  JSON  strings below. Message \"a\" will match filter '1', but message \"b\" will not.", 
            "title": "Filter Matching"
        }, 
        {
            "location": "/documentation/#filter-1", 
            "text": "{ formID : patient_registration_v7 }", 
            "title": "filter 1:"
        }, 
        {
            "location": "/documentation/#message-a-match", 
            "text": "{ submissionDate : 2016-01-15 ,  formID : patient_registration_v7 ,  name : Jack Wilshere ,  dob : 1986-05-16 ,  medications : [ anaphlene , zaradood , morphofast ]}", 
            "title": "message a (MATCH):"
        }, 
        {
            "location": "/documentation/#message-b-no-match", 
            "text": "{ submissionDate : 2016-01-16 ,  formID : patient_registration_v8 ,  name : Larry Bird ,  dob : 1982-03-21 ,  medications : [ anaphlene , zaradood , morphofast ]}  Message 'b' does not include  \"formID\":\"patient_registration_v7\"  and will not match filter '1'.", 
            "title": "message b (NO MATCH):"
        }, 
        {
            "location": "/documentation/#credentials", 
            "text": "Credentials are used to authorize connections to destination systems. In the future, our adaptors will use credentials to fetch meta-data from source and destination applications and make the job writing process easier.  Some systems (Salesforce, OpenMRS, DHIS2) require an instanceUrl, host, or ApiUrl. Leave off the final \"/\" in these Urls: https://login.salesforce.com  or  http://demo.openmrs.org/openmrs  or  https://play.dhis2.org .  Credentials can only be viewed, or edited by a single user \u2014 their \"owner\" (or the person that created that credential). All the collaborators on a particular project can choose those credentials for use when defining a job.", 
            "title": "Credentials"
        }, 
        {
            "location": "/documentation/#jobs", 
            "text": "A job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed.", 
            "title": "Jobs"
        }, 
        {
            "location": "/documentation/#composing-job-expressions", 
            "text": "In most cases, a job expression is a series of  create  or  upsert  actions that are run after a message arrives, using data from that message. It could look like this:  create( Patient__c , fields(\n  field( Name , dataValue( form.surname )),\n  field( Age__c , 7)\n))  That would create a new  Patient__c  in some other system. The patient's  Name  will be determined by the triggering message (the value inside  form.name , specifically) and the patient's  Age__c  will  always  be 7. See how we hard coded it?  What you see above is OpenFn's own syntax, and you've got access to dozens of common \"helper functions\" like  dataValue(path)  and destination specific functions like  create(object,attributes) . While most cases are covered out-of-the-box, jobs are  evaluated as Javascript . This means that you can write your own custom, anonymous functions to do whatever your heart desires:  create( Patient__c , fields(\n  field( Name , function(state) {\n    return Array.apply(\n      null, dataValue( patient_names )(state)\n    ).join(', ')\n  })\n  field( Age__c , 7)  Here, the patient's name will be a comma separated concatenation of all the values in the  patient_names  array from our source message.  Other than the expression tree, Jobs have certain attributes that must be set:   Filter  - The message filter that will triggers the job.  Adaptor  - The adaptor for the destination system you're connecting to.  Credential  - The credential that will be used to gain access to that destination system.  Active?  - A boolean which determines whether the job runs in real-time when matching messages arrive.", 
            "title": "Composing Job Expressions"
        }, 
        {
            "location": "/documentation/#selected-named-functions", 
            "text": "There are lots more available in the language-packs.", 
            "title": "Selected Named Functions"
        }, 
        {
            "location": "/documentation/#language-common", 
            "text": "field('destination_field_name__c', 'value')  Returns a key, value pair in an array.  (source)  fields(list_of_fields)  zips key value pairs into an object.  (source)  dataValue('JSON_path')  Picks out a single value from source data.  (source)  each(JSON_path, operation(...))  Scopes an array of data based on a JSONPath  (source)  beta.each(JSON_path, operation(...))  Pre-release: new feature details coming.  (source)  each(merge(dataPath(\"CHILD_ARRAY[*]\"),fields(field(\"metaId\", dataValue(\"*meta-instance-id*\")),field(\"parentId\", lastReferenceValue(\"id\")))), create(...))  merges data into an array then creates for each item in the array  (source)  lastReferenceValue('id')  gets the sfID of the last item created  (source)  function(state){return state.references[state.references.length-N].id})  gets the sfID of the nth item created", 
            "title": "language-common"
        }, 
        {
            "location": "/documentation/#salesforce", 
            "text": "create(\"DEST_OBJECT_NAME__C\", fields(...))  Create a new object. Takes 2 parameters: An object and attributes.  (source)  upsert(\"DEST_OBJECT_NAME__C\", \"DEST_OBJECT_EXTERNAL_ID__C\", fields(...))  Creates or updates an object. Takes 3 paraneters: An object, an ID field and attributes.  (source)  relationship(\"DEST_RELATIONSHIP_NAME__r\", \"EXTERNAL_ID_ON_RELATED_OBJECT__C\", \"SOURCE_DATA_OR_VALUE\")  Adds a lookup or 'dome insert' to a record.  (source)", 
            "title": "Salesforce"
        }, 
        {
            "location": "/documentation/#dhis2", 
            "text": "event(...)  Creates an event.  (source)  dataValueSet(...)  Send data values using the dataValueSets resource  (source)", 
            "title": "dhis2"
        }, 
        {
            "location": "/documentation/#openmrs", 
            "text": "person(...)  Takes a payload of data to create a person  (source)  patient(...)  Takes a payload of data to create a patient  (source)   For code block examples of job expressions, go to the  Appendix .", 
            "title": "OpenMRS"
        }, 
        {
            "location": "/documentation/#inbox", 
            "text": "Your inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data that were sent via HTTP post to your inbox. They can be viewed in formatted JSON, edited, or manually processed (if they did not match a filter when they were originally delivered.)  To edit a message, click the \"pencil and paper\" icon next to that receipt. Be careful, as no original copy will be persisted.", 
            "title": "Inbox"
        }, 
        {
            "location": "/documentation/#activity", 
            "text": "In this section of the portal, you can view a list of all \"runs\" - i.e. individual job runs. This list is essentially a compilation of all jobs, messages and credentials flowing through your OpenFn account towards your destination system(s).", 
            "title": "Activity"
        }, 
        {
            "location": "/documentation/#runs", 
            "text": "Runs are attempts made on a destination system by running a receipt through a Job Description. Runs can be viewed and re-processed. Each submission has a  success ,  started_at ,  finsihed_at ,  job_description_id , and  receipt_id  attribute.  Started_at  and  finished_at  are the timestamps when the submission began and ended.   Note:  Some runs may take a really long time, particularly if they are performing multiple actions in a destination system or if they are fetching lots of data from a REST api at the start of a migration. They will appear as red if they have failed. In the case of failure, refer to our  Troubleshooting  section below.", 
            "title": "Runs"
        }, 
        {
            "location": "/documentation/#troubleshooting", 
            "text": "What happens if my survey data from ODK needs to link to existing records in my Salesforce system but a respondent enters or selects an invalid  external ID ?   Great question, and don't worry, it happens all the time. Assuming you've already taken all possible measures to either pre-load external IDs in your ODK form or use more human-proof IDs (like barcodes and fingerprints) here's the flow of work:    Read the email, and inspect the reason for failure.    99% of failed runs on OpenFn are due to  value mismatches . The  collected   id  in ODK doesn't match the  expected   id  in Salesforce. You must now chose to either:  A. Edit the source  id  in your  receipt    retry the attempt.  B. Edit the related  id  in your destination system   retry the attempt.  C. Ignore the attempt\u2014this source data will never reach your destination system. (There have been reports of ODK Aggregate's JSON publisher sending dupliate values. If that happens and your run fails due to \"duplicate values\" on a particular unique field you can safely ignore the run in OpenFn.)    Editing data in your destination system can be done through that system's interface. Many tools that act as  sources  (like ODK) do not allow for easy editing and re-submission of data. You can use OpenFn to edit the source data before retrying the attempt.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/documentation/#common-error-messages", 
            "text": "The most common error messages with English explanations are:\n+  DUPLICATE_VALUE: duplicate value found: ODK_uuid__c duplicates value on record with id: a0524000005wNw0  - The insert is blocked because you are attempting to create a new record with a unique field with the same value as an existing record.\n+  Required value missing \n+  ExternalId not found", 
            "title": "Common Error Messages"
        }, 
        {
            "location": "/documentation/#diy", 
            "text": "OpenFn's core ETL tools are all open-source, and here we will explain how those tools can be used to perform ETL operations from your command line. You can even take this further and wrap them together in your own hosted service!   ETL  = Extracting, Transforming and Loading of data   To get started, follow these steps: \n  1. Create an empty directory somewhere on your local machine (e.g. call it \"OpenFn\")\n  2. Open up a terminal, cd into the new directory, and git clone the following:\n    -  git clone   fn-lang \n    -  git clone   language-common \n    -  git clone   language-xxx  (an adaptor of your choice, from github.com/OpenFn)  #### fn-lang (diesl)\nfn-lang is a coordination tool that takes a job expression, a JSON payload, an adaptor, and a configuration file, and runs the \"TL\" part of \"ETL\" on command. It can be run from a command line, or built into a hosted web service.\n\n#### language-common\n`language-common` provides basic data manipulation functionality like `each`, `field`, and `toArray`.\n\n#### language-xxx\n`language-xxx` is a \"destination adaptor\" that knows how to connect to the system in question and provides system-specific operations, like `relationship` or `upsert`. Examples: `language-dhis2`, `language-salesforce`, `language-openmrs`.   cd into 'fn-lang'   type into the terminal the following commands (in order):   npm install  npm link ../language-common  npm link ../language-xxx (Whatever adaptor you chose. For this demonstration we will use DHIS2)     Create a folder named \"tmp\" inside \"fn-lang\".   Inside \"tmp\", you need to create 3 files:  config.json ,  expression.js  and  message.json .    Click  HERE  to get started by using some sample code for each of the 3 files.    Run fn-lang from the command line with the following:   ~/fn-lang$ lib/cli.js execute -l dhis2 -e tmp/expression.js -c tmp/config.json -d tmp/message.json  Command Explained:  Execute an expression (-e) and load on some data (-d) using a language-pack (-l) and a destination configuration file (-c).   Note:  Depending on which language-pack you have decided to use, you will need to change this command by replacing \"dhis2\" with the name of the language-pack you are using. E.g. \"openmrs\" or \"salesforce/FakeAdaptor\" (special case).    Check out the results of the posted data! Open up expression.js and message.json to manipulate the outcome and get a feel for how it works.", 
            "title": "DIY"
        }, 
        {
            "location": "/documentation/#appendix", 
            "text": "", 
            "title": "Appendix"
        }, 
        {
            "location": "/documentation/#sample-code-for-diy-section", 
            "text": "Below you can find sample code to fill the 3 files required to run fn-lang -  message.json ,  expression.js  and  config.json .", 
            "title": "Sample code for DIY section"
        }, 
        {
            "location": "/documentation/#messagejson", 
            "text": "{\n   xform_ids : [],\n   version : null,\n   user_id :  user1 ,\n   server_date_opened : null,\n   server_date_modified : null,\n   properties : {\n     prop_c :  2013-05-18 ,\n     prop_b :  Female ,\n     prop_a : 99,\n     owner_id : null,\n     external_id : null,\n     date_opened : null,\n     date :  2013-05-17 ,\n     case_type :  case_type ,\n     case_name :  Demo \n  },\n   indices : {}\n}", 
            "title": "message.json"
        }, 
        {
            "location": "/documentation/#expressionjs", 
            "text": "event(\n  fields(\n    field( program ,  eBAyeGv0exc ),\n    field( orgUnit ,  DiszpKrYNg8 ),\n    field( eventDate , dataValue( properties.date )),\n    field( status ,  COMPLETED ),\n    field( storedBy ,  admin ),\n    field( coordinate , {\n       latitude :  59.8 ,\n       longitude :  10.9 \n    }),\n    field( dataValues , function(state) {\n      return [\n        {  dataElement :  qrur9Dvnyt5 ,  value : dataValue( properties.prop_a )(state) },\n        {  dataElement :  oZg33kd9taw ,  value : dataValue( properties.prop_b )(state) },\n        {  dataElement :  msodh3rEMJa ,  value : dataValue( properties.prop_c )(state) }\n      ]\n    })\n  )\n)", 
            "title": "expression.js"
        }, 
        {
            "location": "/documentation/#configjson", 
            "text": "{\n   username :  admin ,\n   password :  district ,\n   apiUrl :  https://play.dhis2.org/demo \n}", 
            "title": "config.json"
        }, 
        {
            "location": "/documentation/#more-example-filters", 
            "text": "", 
            "title": "More example filters"
        }, 
        {
            "location": "/documentation/#match-messages-where-the-formid-is-robot_photo_21042015", 
            "text": "{ formId : Robot_Photo_21.04.2015 }", 
            "title": "Match messages WHERE the formId is \"Robot_Photo_21.04.2015\":"
        }, 
        {
            "location": "/documentation/#match-a-message-where-this-and-that-are-both-included", 
            "text": "{ formId : Robot_Photo_21.04.2015 ,  secret_number :8}", 
            "title": "Match a message WHERE this AND that are both included:"
        }, 
        {
            "location": "/documentation/#match-a-message-with-two-fragments-inside-an-array-called-data", 
            "text": "(This is useful when gathering data via ODK)  { data :[{ outlet_call : TRUE , new_existing : Existing }]}", 
            "title": "Match a message with two fragments inside an array called data:"
        }, 
        {
            "location": "/documentation/#match-a-message-with-a-fragment-inside-another-object-called-form", 
            "text": "{ form :{ @xmlns : http://openrosa.org/formdesigner/F732194-3278-nota-ReAL-one }}", 
            "title": "Match a message with a fragment inside another object called form:"
        }, 
        {
            "location": "/documentation/#more-example-jobs", 
            "text": "Below you can find some examples of block code for different functions and data handling contexts.", 
            "title": "More example jobs"
        }, 
        {
            "location": "/documentation/#job-expression-for-commcare-to-sf", 
            "text": "The following job expression will take a matching receipt and use data from that receipt to upsert a  Patient__c  record in Salesforce and create multiple new  Patient_Visit__c  (child to Patient) records.  upsert( Patient__c ,  Patient_Id__c , fields(\n  field( Patient_Id__c , dataValue( form.patient_ID )),\n  relationship( Nurse__r ,  Nurse_ID_code__c , dataValue( form.staff_id )),\n  field( Phone_Number__c , dataValue( form.mobile_phone ))\n)),\neach(\n  join( $.data.form.visits[*] ,  $.references[0].id ,  Id ),\n  create( Visit__c , fields(\n    field( Patient__c , dataValue( Id )),\n    field( Date__c , dataValue( date )),\n    field( Reason__c , dataValue( why_did_they_see_doctor ))\n  ))\n)", 
            "title": "Job expression (for CommCare to SF)"
        }, 
        {
            "location": "/documentation/#accessing-the-data-array-in-open-data-kit-submissions", 
            "text": "Notice how we use \"each\" to get data from each item inside the \"data array\" in ODK.  each(\n   $.data.data[*] ,\n  create( ODK_Submission__c , fields(\n    field( Site_School_ID_Number__c , dataValue( school )),\n    field( Date_Completed__c , dataValue( date )),\n    field( comments__c , dataValue( comments )),\n    field( ODK_Key__c , dataValue( *meta-instance-id* ))\n  ))\n)", 
            "title": "Accessing the \"data array\" in Open Data Kit submissions"
        }, 
        {
            "location": "/documentation/#odk-to-salesforce-create-parent-record-with-many-children-from-parent-data", 
            "text": "Here, the user brings  time_end  and  parentId  onto the line items from the parent object.  each(\n  dataPath( data[*] ),\n  combine(\n    create( transaction__c , fields(\n      field( Transaction_Date__c , dataValue( today )),\n      relationship( Person_Responsible__r ,  Staff_ID_Code__c , dataValue( person_code )),\n      field( metainstanceid__c , dataValue( *meta-instance-id* ))\n    )),\n    each(\n      merge(dataPath( line_items[*] ), fields(\n        field( end , dataValue( time_end )),\n        field( parentId , lastReferenceValue( id ))\n      )),\n      create( line_item__c , fields(\n        field( transaction__c , dataValue( parentId )),\n        field( Barcode__c , dataValue( product_barcode )),\n        field( ODK_Form_Completed__c , dataValue( end ))\n      ))\n    )\n  )\n)   NB - there was a known bug with the  combine  function which has been resolved.  combine  can be used to combine two operations into one and is commonly used to run multiple  create 's inside an  each(path, operation) . The source code for combine can be found here:  language-common: combine", 
            "title": "ODK to Salesforce: create parent record with many children from parent data"
        }, 
        {
            "location": "/documentation/#create-many-child-records-without-a-repeat-group-in-odk", 
            "text": "beta.each(\n   $.data.data[*] ,\n  upsert( Outlet__c ,  Outlet_Code__c , fields(\n    field( Outlet_Code__c , dataValue( outlet_code )),\n    field( Location__Latitude__s , dataValue( gps:Latitude )),\n    field( Location__Longitude__s , dataValue( gps:Longitude ))\n  ))\n),\nbeta.each(\n     $.data.data[*] ,\n    upsert( Outlet_Call__c ,  Invoice_Number__c , fields(\n      field( Invoice_Number__c , dataValue( invoice_number )),\n      relationship( Outlet__r ,  Outlet_Code__c , dataValue( outlet_code )),\n      relationship( RecordType ,  name ,  No Call Card ),\n      field( Trip__c ,  a0FN0000008jPue ),\n      relationship( Sales_Person__r ,  Sales_Rep_Code__c , dataValue( sales_rep_code )),\n      field( Date__c , dataValue( date )),\n      field( Comments__c , dataValue( comments ))\n  ))\n)", 
            "title": "Create many child records WITHOUT a repeat group in ODK"
        }, 
        {
            "location": "/documentation/#salesforce-set-record-type-using-relationship", 
            "text": "create( custom_obj__c , fields(\n            relationship( RecordType ,  name , dataValue( submission_type ),\n            field( name , dataValue( Name ))\n            )\n      ))", 
            "title": "Salesforce: Set record type using 'relationship(...)'"
        }, 
        {
            "location": "/documentation/#salesforce-set-record-type-using-record-type-id", 
            "text": "each(\n   $.data.data[*] ,\n  create( fancy_object__c , fields(\n    field( RecordTypeId ,  012110000008s19 ),\n    field( site_size , dataValue( size ))\n  ))\n)", 
            "title": "Salesforce: Set record type using record Type ID"
        }, 
        {
            "location": "/documentation/#telerivet-send-sms-based-on-salesforce-workflow-alert", 
            "text": "send(\n  fields(\n    field( to_number , dataValue( Envelope.Body.notifications.Notification.sObject.phone_number__c )),\n    field( message_type ,  sms ),\n    field( route_id ,  ),\n    field( content , function(state) {\n      return (\n         Hey there. Your name is  .concat(\n          dataValue( Envelope.Body.notifications.Notification.sObject.name__c )(state),\n           . \n        )\n      )\n    })\n  )\n)", 
            "title": "Telerivet: Send SMS based on Salesforce workflow alert"
        }, 
        {
            "location": "/documentation/#sample-dhis2-events-api-job", 
            "text": "event(\n  fields(\n    field( program ,  eBAyeGv0exc ),\n    field( orgUnit ,  DiszpKrYNg8 ),\n    field( eventDate , dataValue( properties.date )),\n    field( status ,  COMPLETED ),\n    field( storedBy ,  admin ),\n    field( coordinate , {\n       latitude :  59.8 ,\n       longitude :  10.9 \n    }),\n    field( dataValues , function(state) {\n      return [\n        {  dataElement :  qrur9Dvnyt5 ,  value : dataValue( properties.prop_a )(state) },\n        {  dataElement :  oZg33kd9taw ,  value : dataValue( properties.prop_b )(state) },\n        {  dataElement :  msodh3rEMJa ,  value : dataValue( properties.prop_c )(state) }\n      ]\n    })\n  )\n)", 
            "title": "Sample DHIS2 events API job:"
        }, 
        {
            "location": "/documentation/#sample-dhis2-data-value-sets-api-job", 
            "text": "dataValueSet(\n  fields(\n    field( dataSet ,  pBOMPrpg1QX ),\n    field( orgUnit ,  DiszpKrYNg8 ),\n    field( period ,  201401 ),\n    field( completeData , dataValue( date )),\n    field( dataValues , function(state) {\n      return [\n        {  dataElement :  f7n9E0hX8qk ,  value : dataValue( prop_a )(state) },\n        {  dataElement :  Ix2HsbDMLea ,  value : dataValue( prop_b )(state) },\n        {  dataElement :  eY5ehpbEsB7 ,  value : dataValue( prop_c )(state) }\n      ]\n    })\n  )\n)", 
            "title": "Sample DHIS2 data value sets API job:"
        }, 
        {
            "location": "/documentation/#sample-openmrs-expression-creates-a-person-and-then-a-patient", 
            "text": "person(\n  fields(\n    field( gender ,  F ),\n    field( names , function(state) {\n      return [{\n         givenName : dataValue( form.first_name )(state),\n         familyName : dataValue( form.last_name )(state)\n      }]\n    })\n  )\n),\npatient(\n  fields(\n    field( person , lastReferenceValue( uuid )),\n    field( identifiers , function(state) {\n      return [{\n         identifier :  1234 ,\n         identifierType :  8d79403a-c2cc-11de-8d13-0010c6dffd0f ,\n         location :  8d6c993e-c2cc-11de-8d13-0010c6dffd0f ,\n         preferred : true\n      }]\n    })\n  )\n)", 
            "title": "sample openMRS expression, creates a person and then a patient"
        }, 
        {
            "location": "/documentation/#examples-of-anonymous-functions", 
            "text": "Different to  Named Functions , Anoynmous functions are generic pieces of javascript which you can write to suit your needs. Here are some examples of these custom functions:", 
            "title": "Examples of Anonymous Functions"
        }, 
        {
            "location": "/documentation/#custom-replacer", 
            "text": "field(\n   destination__c ,\n  function(state){\n    return dataValue( path_to_data )(state).toString().replace( cats , dogs )\n  }\n)  This will replace all \"cats\" with \"dogs\" in the string that lives at  path_to_data .   NOTE:  The JavaScript  replace()  function only replaces the first instance of whatever argument you specify.\nIf you're looking for a way to replace all instances, we suggest you use a regex like we did in the  example  below.", 
            "title": "Custom replacer"
        }, 
        {
            "location": "/documentation/#custom-arraytostring", 
            "text": "field( target_specie_list__c , function(state) {\n  return Array.apply(\n    null, sourceValue( $.data.target_specie_list )(state)\n  ).join(', ')\n}),  It will take an array, and concatenate each item into a string with a \", \" separator.", 
            "title": "Custom arrayToString"
        }, 
        {
            "location": "/documentation/#custom-concatenation", 
            "text": "field( ODK_Key__c , function (state) {\n  return (\n    dataValue( metaId )(state).concat(\n       ( , dataValue( index )(state),  ) \n    )\n  )\n})  This will concatenate two values.", 
            "title": "Custom concatenation"
        }, 
        {
            "location": "/documentation/#custom-concatenation-of-null-values", 
            "text": "This will concatenate many values, even if one or more are null, writing them to a field called Main_Office_City_c.  ...\n  field( Main_Office_City__c , function(state) {\n    return arrayToString([\n      dataValue( Main_Office_City_a )(state) === null ?   : dataValue( Main_Office_City_a )(state).toString().replace(/-/g,    ),\n      dataValue( Main_Office_City_b )(state) === null ?   : dataValue( Main_Office_City_b )(state).toString().replace(/-/g,    ),\n      dataValue( Main_Office_City_c )(state) === null ?   : dataValue( Main_Office_City_c )(state).toString().replace(/-/g,    ),\n      dataValue( Main_Office_City_d )(state) === null ?   : dataValue( Main_Office_City_d )(state).toString().replace(/-/g,    ),\n    ].filter(Boolean), ',')\n  })   Notice how this custom function makes use of the  regex   /-/g  to ensure that all instances are accounted for (g = global search).", 
            "title": "Custom concatenation of null values"
        }, 
        {
            "location": "/documentation/#custom-nth-reference-id", 
            "text": "If you ever want to retrieve the FIRST object you created, or the SECOND, or the Nth, for that matter, a function like this will do the trick.  field( parent__c , function(state) {\n    return state.references[state.references.length-1].id\n  })  See how instead of taking the id of the \"last\" thing that was created in Salesforce, you're taking the id of the 1st thing, or 2nd thing if you replace \"length-1\" with \"length-2\".", 
            "title": "Custom Nth reference ID"
        }, 
        {
            "location": "/documentation/#convert-date-string-to-standard-iso-date-for-salesforce", 
            "text": "field( Payment_Date__c , function(state) {\n  return new Date(dataValue( payment_date )(state)).toISOString()\n})   NOTE : The output of this function will always be formatted according to GMT time-zone.", 
            "title": "Convert date string to standard ISO date for Salesforce"
        }, 
        {
            "location": "/source-applications/", 
            "text": "Setting up real-time sources\n\n\nThis section describes how to enable push notifications from selected source applications. Many web apps have some sort of events-based notifications engine. If you don't see yours listed below feel free to add it with a pull request.\n\n\nOpen Data Kit (ODK) Aggregate\n\n\n\n\nTo new submissions from ODK in real-time, click the \"Form Management\" tab at the top of your Aggregate interface.\n\n\nClick \"Publish\" next to the form you'd like to publish to OpenFn.\n\n\nA dialogue box will open.\n\n\nIn the \"Publish To:\" picklist, select \nZ-ALPHA JSON Server\n.\n\n\nChoose which data to publish in the \"Data to Publish:\" picklist. You may: \n\"Upload Existing Data ONLY\"\n (ideal for migrations of finished data sets), \n\"Stream New Submission Data ONLY\"\n (ideal for new projects), or \n\"BOTH Upload Existing \n Stream New Submission Data\"\n (ideal for connecting ongoing projects which are already running).\n\n\nIn the \"URL to publish to:\" text box, enter your OpenFn Inbox UUID. (e.g., \nhttps://www.openfn.org/inbox/8ad63a29-mUCh-sEcRET-cODes-wOW\n)\n\n\nLeave \"Authorization token:\" blank.\n\n\nLeave \"Include Media as:\" set to \"Links(URLs) to Media\".\n\n\nClick \"Publish\" and enter your email address in the dialogue box.\n\n\nClick the \"Published Data\" tab under \"Form Management\" and select your form to view the status of your publisher. You can also now check your OpenFn inbox to see ODK submissions arrive.\n\n\n\n\nKobo\n\n\n\n\nTo push data from Kobo, users must click the projects icon on their left-side nav bar. It's in the shape of a globe.\n\n\nOnce selecting a project, the \nProject Settings\n link will appear at the top left side of the screen. Click it to open the Project Settings page.\n\n\nIn the bottom left pane of the project settings page, users must paste their inbox URL from OpenFn into the \nRest Services\n \nService URL\n input area and select \nJSON Post\n as the \nService Name\n.\n\n\nClick \nAdd Service\n to start forwarding new Kobo submissions to OpenFn.org.\n\n\n\n\nTo test to integration, add a submission manually using the \nenter data in browser\n button. Head back to your history page at OpenFn to view the newly submitted data and write a new \nfilter\n and \njob\n to map your Kobo data to any destination system on OpenFn.\n\n\nHere's a sample post from Kobo REST service. Note that questions inside groups are prefixed with \ngroupname/\n rather than sitting inside a group object like ODK:\n\n\n{\n  \nmeta/instanceID\n: \nuuid:19d72997-8316-4e02-8016-4a8ddf6a2aa4\n,\n  \ngroup1/name\n: \ntwenty\n,\n  \ngroup1/age\n: \n19\n,\n  \nformhub/uuid\n: \n6f5773a110b046cb97e3d71f6c04e7a6\n,\n  \nfirst_q\n: \nhello\n,\n  \nfinal_q\n: \nwhy not?\n,\n  \n_xform_id_string\n: \ngroups\n,\n  \n_uuid\n: \n19d72997-8316-4e02-8016-4a8ddf6a2aa4\n,\n  \n_userform_id\n: \ntaylordowns2000_groups\n,\n  \n_tags\n: [],\n  \n_submitted_by\n: null,\n  \n_submission_time\n: \n2016-04-22T06:38:20\n,\n  \n_status\n: \nsubmitted_via_web\n,\n  \n_notes\n: [],\n  \n_id\n: 889409,\n  \n_geolocation\n: [\n    null,\n    null\n  ],\n  \n_bamboo_dataset_id\n: \n,\n  \n_attachments\n: []\n}", 
            "title": "Source Application Setup"
        }, 
        {
            "location": "/source-applications/#setting-up-real-time-sources", 
            "text": "This section describes how to enable push notifications from selected source applications. Many web apps have some sort of events-based notifications engine. If you don't see yours listed below feel free to add it with a pull request.", 
            "title": "Setting up real-time sources"
        }, 
        {
            "location": "/source-applications/#open-data-kit-odk-aggregate", 
            "text": "To new submissions from ODK in real-time, click the \"Form Management\" tab at the top of your Aggregate interface.  Click \"Publish\" next to the form you'd like to publish to OpenFn.  A dialogue box will open.  In the \"Publish To:\" picklist, select  Z-ALPHA JSON Server .  Choose which data to publish in the \"Data to Publish:\" picklist. You may:  \"Upload Existing Data ONLY\"  (ideal for migrations of finished data sets),  \"Stream New Submission Data ONLY\"  (ideal for new projects), or  \"BOTH Upload Existing   Stream New Submission Data\"  (ideal for connecting ongoing projects which are already running).  In the \"URL to publish to:\" text box, enter your OpenFn Inbox UUID. (e.g.,  https://www.openfn.org/inbox/8ad63a29-mUCh-sEcRET-cODes-wOW )  Leave \"Authorization token:\" blank.  Leave \"Include Media as:\" set to \"Links(URLs) to Media\".  Click \"Publish\" and enter your email address in the dialogue box.  Click the \"Published Data\" tab under \"Form Management\" and select your form to view the status of your publisher. You can also now check your OpenFn inbox to see ODK submissions arrive.", 
            "title": "Open Data Kit (ODK) Aggregate"
        }, 
        {
            "location": "/source-applications/#kobo", 
            "text": "To push data from Kobo, users must click the projects icon on their left-side nav bar. It's in the shape of a globe.  Once selecting a project, the  Project Settings  link will appear at the top left side of the screen. Click it to open the Project Settings page.  In the bottom left pane of the project settings page, users must paste their inbox URL from OpenFn into the  Rest Services   Service URL  input area and select  JSON Post  as the  Service Name .  Click  Add Service  to start forwarding new Kobo submissions to OpenFn.org.   To test to integration, add a submission manually using the  enter data in browser  button. Head back to your history page at OpenFn to view the newly submitted data and write a new  filter  and  job  to map your Kobo data to any destination system on OpenFn.  Here's a sample post from Kobo REST service. Note that questions inside groups are prefixed with  groupname/  rather than sitting inside a group object like ODK:  {\n   meta/instanceID :  uuid:19d72997-8316-4e02-8016-4a8ddf6a2aa4 ,\n   group1/name :  twenty ,\n   group1/age :  19 ,\n   formhub/uuid :  6f5773a110b046cb97e3d71f6c04e7a6 ,\n   first_q :  hello ,\n   final_q :  why not? ,\n   _xform_id_string :  groups ,\n   _uuid :  19d72997-8316-4e02-8016-4a8ddf6a2aa4 ,\n   _userform_id :  taylordowns2000_groups ,\n   _tags : [],\n   _submitted_by : null,\n   _submission_time :  2016-04-22T06:38:20 ,\n   _status :  submitted_via_web ,\n   _notes : [],\n   _id : 889409,\n   _geolocation : [\n    null,\n    null\n  ],\n   _bamboo_dataset_id :  ,\n   _attachments : []\n}", 
            "title": "Kobo"
        }, 
        {
            "location": "/release-notes/", 
            "text": "Version 1.2.0 (2016-09-15)\n\n\n\n\nUsers can now select specific adaptor versions for their jobs.\n\n\nJobs will \"auto-upgrade\" unless locked to a specific version.\n\n\n\n\nAdaptor versions:\n  This means that the code beneath your job, once saved with a specific adaptor version, will never change. This is an important step forward for the whole community, as it enables more rapid progress\u2014especially considering the growing number of outside contributors\u2014without risking introducing instability to existing jobs.\n\n\nEach new version of an adaptor will have release notes introducing the new features or changes to helper functions. To allow easy upgrades, we will still mandate that all new versions are backwards compatible. \n\n\nVersion 1.1.0 (2016-08-29)\n\n\nNew features:\n\n\n\n\nUsers can now run jobs based on \ntimers\n as well as filters.\n\n\nUsers can now view logs for all runs, not just the most recent.\n\n\nJobs are \"aware\" of their last running state.\n\n\nget(...)\n and \npost(...)\n are now supported using the language-http adaptor, allowing users to make their own HTTP calls in jobs.\n\n\n\n\nTimer triggers:\n On the triggers tab, users can set the trigger type to \"timer\" and input a whole number of seconds for the \"interval\". Any \"active\" jobs associated with this trigger will run periodically after the interval elapses.\n\n\nView logs for all runs:\n By clicking on an individual run from either the Activity tab or the Message Inspector, users can view the full logs for that run, regardless of whether or not a more recent run took place with the same job and message.\n\n\nJob state:\n When a job runs based on a timer, not an incoming message, it will preserve it's state for the next run. This feature is commonly used by language packs like language-surveycto, language-odk, and others to create a \"cursor\" to offset or limit database queries.\n\n\n\n\nFor example, \nfetchSubmissions(...)\n in the language-surveycto adaptor takes three arguments: \nformId\n, \nafterDate\n, and \npostUrl\n. The first time this job runs it will only fetch submissions \nafter\n the \nafterDate\n. If any submissions are received, it will take the last submission from the array (by date) and persist it in the \njob_state\n as \nlastSubmissionDate\n. The next time this job runs, say, 300 seconds (5 minutes) later, it will ignore \nafterDate\n and instead fetch submissions after \nlastSubmissionDate\n. While this particular helper function is very abstract (it does this one thing well) it's possible to write a job that simply alters the final \"state\" before completing, passing whatever data you'd like from \nTHIS RUN\n to the \nNEXT RUN\n of the job.\n\n\n\n\nget(...) and post(...):\n Have a look at this complex job using language-http. See how it is possible to provide a query and a callback for \nget\n while \npost\n takes a url and a body object. At the end, the user is setting state.lastSubmissionDate to \nsubmissions[submissions.length-1].SubmissionDate\n.\n\n\nSee the functions themselves at \nlanguage-http\n.\n\n\nget(\nforms/data/wide/json/someForm\n, {\n  query: function(state) {\n    return { date: state.lastSubmissionDate || \nAug 29, 2016 4:44:26 PM\n}\n  },\n  callback: function(state) {\n    // Pick submissions out in order to avoid `post` overwriting `response`.\n    var submissions = state.response.body;\n    // return submissions\n    return submissions.reduce(function(acc, item) {\n        // tag submissions as part of the \nsomeForm\n form\n        item.formId = \nsomeForm\n\n        return acc.then(\n          post(\n            \nhttps://www.openfn.org/inbox/some-inbox-uuid\n,\n            { body: item }\n          )\n        )\n      }, Promise.resolve(state))\n      .then(function(state) {\n        if (submissions.length) {\n          state.lastSubmissionDate = submissions[submissions.length-1].SubmissionDate\n        }\n        return state;\n      })\n      .then(function(state) {\n        delete state.response\n        return state;\n      })\n  }\n})", 
            "title": "Release Notes"
        }, 
        {
            "location": "/release-notes/#version-120-2016-09-15", 
            "text": "Users can now select specific adaptor versions for their jobs.  Jobs will \"auto-upgrade\" unless locked to a specific version.   Adaptor versions:   This means that the code beneath your job, once saved with a specific adaptor version, will never change. This is an important step forward for the whole community, as it enables more rapid progress\u2014especially considering the growing number of outside contributors\u2014without risking introducing instability to existing jobs.  Each new version of an adaptor will have release notes introducing the new features or changes to helper functions. To allow easy upgrades, we will still mandate that all new versions are backwards compatible.", 
            "title": "Version 1.2.0 (2016-09-15)"
        }, 
        {
            "location": "/release-notes/#version-110-2016-08-29", 
            "text": "New features:   Users can now run jobs based on  timers  as well as filters.  Users can now view logs for all runs, not just the most recent.  Jobs are \"aware\" of their last running state.  get(...)  and  post(...)  are now supported using the language-http adaptor, allowing users to make their own HTTP calls in jobs.   Timer triggers:  On the triggers tab, users can set the trigger type to \"timer\" and input a whole number of seconds for the \"interval\". Any \"active\" jobs associated with this trigger will run periodically after the interval elapses.  View logs for all runs:  By clicking on an individual run from either the Activity tab or the Message Inspector, users can view the full logs for that run, regardless of whether or not a more recent run took place with the same job and message.  Job state:  When a job runs based on a timer, not an incoming message, it will preserve it's state for the next run. This feature is commonly used by language packs like language-surveycto, language-odk, and others to create a \"cursor\" to offset or limit database queries.   For example,  fetchSubmissions(...)  in the language-surveycto adaptor takes three arguments:  formId ,  afterDate , and  postUrl . The first time this job runs it will only fetch submissions  after  the  afterDate . If any submissions are received, it will take the last submission from the array (by date) and persist it in the  job_state  as  lastSubmissionDate . The next time this job runs, say, 300 seconds (5 minutes) later, it will ignore  afterDate  and instead fetch submissions after  lastSubmissionDate . While this particular helper function is very abstract (it does this one thing well) it's possible to write a job that simply alters the final \"state\" before completing, passing whatever data you'd like from  THIS RUN  to the  NEXT RUN  of the job.   get(...) and post(...):  Have a look at this complex job using language-http. See how it is possible to provide a query and a callback for  get  while  post  takes a url and a body object. At the end, the user is setting state.lastSubmissionDate to  submissions[submissions.length-1].SubmissionDate .  See the functions themselves at  language-http .  get( forms/data/wide/json/someForm , {\n  query: function(state) {\n    return { date: state.lastSubmissionDate ||  Aug 29, 2016 4:44:26 PM }\n  },\n  callback: function(state) {\n    // Pick submissions out in order to avoid `post` overwriting `response`.\n    var submissions = state.response.body;\n    // return submissions\n    return submissions.reduce(function(acc, item) {\n        // tag submissions as part of the  someForm  form\n        item.formId =  someForm \n        return acc.then(\n          post(\n             https://www.openfn.org/inbox/some-inbox-uuid ,\n            { body: item }\n          )\n        )\n      }, Promise.resolve(state))\n      .then(function(state) {\n        if (submissions.length) {\n          state.lastSubmissionDate = submissions[submissions.length-1].SubmissionDate\n        }\n        return state;\n      })\n      .then(function(state) {\n        delete state.response\n        return state;\n      })\n  }\n})", 
            "title": "Version 1.1.0 (2016-08-29)"
        }
    ]
}