{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"This documentation is for OpenFn.org , and is primarily intended to help users of the site. Technical documentation for OpenFn's open-source integration tools and language-packs can be found in their respective repositories at Github.com/OpenFn . There are five sections in this documentation site: an introduction (you are here), detailed documentation, GitHub version control documentation, source application setup walkthroughs, and release notes. You Can Contribute If you want a new feature or find a bug, please submit an issue . If you find an issue with the documentation or want to share your custom functions, you can make those changes yourself and submit a pull request ! If you have any questions, please don't hesitate to email admin@openfn.org . The OpenFn Google Group # Please make sure to check out the OpenFn Google Group if you've got questions that aren't answered here. FAQs # What is OpenFn? # OpenFn is an integration platform as a service . This means our prime directive is to move data quickly and securely between different software systems. In most cases: A source application sends messages to your project\u2019s inbox when something happens. Jobs will be triggered, based on your filters , and use the data in those messages to attempt specific actions in destination systems. The logs are recorded so you can see precisely what happened and when and where it happened to take action in the event of a failed attempt\u2014like editing the job or even the source message and trying it again. Who uses OpenFn? # OpenFn is used by organizations big and small, but the individuals interacting with the platform range from system administrators to Javascript developers. With a basic understanding of Javascript, the flexibility of the platform is almost limitless. Is OpenFn open-source? # OpenFn has built and maintains dozens of open-source data transformation and API wrapper software packages. They are licensed under the LGPL and can be used freely to extract, transform, and load data from a command line, or as part of another software application. OpenFn also hosts a proprietary web-application that ties these tools together (www.openfn.org) into an out-of-the-box integration management platform. How reliable is the hosted service? # OpenFn has harnessed the extreme stability and scalability of Erlang to coordinate these actions and provide users with email alerts, project management tools, and an online job writing IDE. We constantly monitor our own status with independent infrastructure at status.openfn.org . You can subscribe to notifications there or follow @openfnstatus . We've been delivering this service continuously since 2014.","title":"Introduction"},{"location":"index.html#the-openfn-google-group","text":"Please make sure to check out the OpenFn Google Group if you've got questions that aren't answered here.","title":"The OpenFn Google Group"},{"location":"index.html#faqs","text":"","title":"FAQs"},{"location":"index.html#what-is-openfn","text":"OpenFn is an integration platform as a service . This means our prime directive is to move data quickly and securely between different software systems. In most cases: A source application sends messages to your project\u2019s inbox when something happens. Jobs will be triggered, based on your filters , and use the data in those messages to attempt specific actions in destination systems. The logs are recorded so you can see precisely what happened and when and where it happened to take action in the event of a failed attempt\u2014like editing the job or even the source message and trying it again.","title":"What is OpenFn?"},{"location":"index.html#who-uses-openfn","text":"OpenFn is used by organizations big and small, but the individuals interacting with the platform range from system administrators to Javascript developers. With a basic understanding of Javascript, the flexibility of the platform is almost limitless.","title":"Who uses OpenFn?"},{"location":"index.html#is-openfn-open-source","text":"OpenFn has built and maintains dozens of open-source data transformation and API wrapper software packages. They are licensed under the LGPL and can be used freely to extract, transform, and load data from a command line, or as part of another software application. OpenFn also hosts a proprietary web-application that ties these tools together (www.openfn.org) into an out-of-the-box integration management platform.","title":"Is OpenFn open-source?"},{"location":"index.html#how-reliable-is-the-hosted-service","text":"OpenFn has harnessed the extreme stability and scalability of Erlang to coordinate these actions and provide users with email alerts, project management tools, and an online job writing IDE. We constantly monitor our own status with independent infrastructure at status.openfn.org . You can subscribe to notifications there or follow @openfnstatus . We've been delivering this service continuously since 2014.","title":"How reliable is the hosted service?"},{"location":"core.html","text":"Job Execution # Introduction # This is technical documentation aimed at making complex custom jobs easier to write. Key Terms and Concepts # core (https://github.com/openfn/core) is the Javascript program which executes jobs for OpenFn in an emphemeral Node.js environment. state is a .JSON file that is built and passed into the Node environment. It contains at least two keys, configuration and data . Configuration will be populated with your credential and it used by language packages for authentication, and data will be populated with message data if the job was triggered by an incoming message. 1 2 3 4 5 6 7 8 9 10 11 12 13 { configuration : { username : taylor , password : shhhhhh , loginUrl : https://login.salesforce.com }, data : { a : 1 , b : { x : [ 1 , 2 , 3 ] } } } expressions are sequences of operations to be executed. They are part of \"jobs\", which also include a credential, a trigger, a label, and (sometimes) a github filepath. operations are named functions, exported for use by specific language-packages, which take state and return state. State is passed to operations. Operations Return state. # This is a key concept. When you write: 1 2 3 create ( object , fields ( field (...) )); The execute function in your language-package (e.g., language-salesforce ) will execute each operation with state, then return state. If you want to execute operations inside another custom function, you must explicitly pass in state. 1 2 3 4 5 alterState ( state = { return create ( object , fields ( field (...) ))( state ) }); Sequences of operations inside custom functions. # Using execute you can string together several sequential operations inside a custom function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 alterState ( state = { const { userName } = state . data . form . meta ; if ( userName != tester ) { return execute ( upsert ( person__c , Name , fields ( field (...), field (...) )), beta . each ( dataPath ( form.array[*] ), upsert ( object , Name , fields ( field (...) )) ) )( state ) } return state ; });","title":"Job Execution"},{"location":"core.html#job-execution","text":"","title":"Job Execution"},{"location":"core.html#introduction","text":"This is technical documentation aimed at making complex custom jobs easier to write.","title":"Introduction"},{"location":"core.html#key-terms-and-concepts","text":"core (https://github.com/openfn/core) is the Javascript program which executes jobs for OpenFn in an emphemeral Node.js environment. state is a .JSON file that is built and passed into the Node environment. It contains at least two keys, configuration and data . Configuration will be populated with your credential and it used by language packages for authentication, and data will be populated with message data if the job was triggered by an incoming message. 1 2 3 4 5 6 7 8 9 10 11 12 13 { configuration : { username : taylor , password : shhhhhh , loginUrl : https://login.salesforce.com }, data : { a : 1 , b : { x : [ 1 , 2 , 3 ] } } } expressions are sequences of operations to be executed. They are part of \"jobs\", which also include a credential, a trigger, a label, and (sometimes) a github filepath. operations are named functions, exported for use by specific language-packages, which take state and return state.","title":"Key Terms and Concepts"},{"location":"core.html#state-is-passed-to-operations-operations-return-state","text":"This is a key concept. When you write: 1 2 3 create ( object , fields ( field (...) )); The execute function in your language-package (e.g., language-salesforce ) will execute each operation with state, then return state. If you want to execute operations inside another custom function, you must explicitly pass in state. 1 2 3 4 5 alterState ( state = { return create ( object , fields ( field (...) ))( state ) });","title":"State is passed to operations. Operations Return state."},{"location":"core.html#sequences-of-operations-inside-custom-functions","text":"Using execute you can string together several sequential operations inside a custom function. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 alterState ( state = { const { userName } = state . data . form . meta ; if ( userName != tester ) { return execute ( upsert ( person__c , Name , fields ( field (...), field (...) )), beta . each ( dataPath ( form.array[*] ), upsert ( object , Name , fields ( field (...) )) ) )( state ) } return state ; });","title":"Sequences of operations inside custom functions."},{"location":"documentation.html","text":"Platform Docs # Quick-start guide # 1. Create your account. If you haven't already, create an account at OpenFn.org 2. Log In. After logging into your new account, you will see an overview of your current projects and the job runs associated with that project. This is called the outer Dashboard . Click on one project to start. 3. Review the navigation bar. You should now be looking at the OpenFn User dashboard for a particular project. Review the following navigation tabs: Jobs | Triggers | Credentials | Inbox | Run History | Version Control | Access Security | Project Settings Jobs. A job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed. Jobs are like the \u201cinstructions\u201d you might give a data entry staff member (e.g., create new Patient record in the database, send SMS with payment confirmation number, etc.). Triggers. A trigger runs jobs based on events, including incoming messages (this is known as a \u201cmessage filter\u201d) or on a timer (a \u201ctime trigger\u201d). Credentials. A credential is used to authorize connection to a destination system (e.g., Salesforce username, password login URL). Inbox. Your inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data (e.g., an incoming SMS, a submitted CommCare form) that were sent via HTTP post to your inbox. Run History. Runs are OpenFn attempts made on a destination system by running a message through a job. Runs can be viewed here and re-processed if there were any errors flagged when running a job. Version Control. Sync your project with a GitHub repository so that every change is tracked using git and jobs can be 'rolled back' to previous commits at the touch of a button. Access Security. - Invite other OpenFn users to collaborate with you on your project and create authentication methods for your project to restrict which applications can send data to your inbox. Settings. Monitor your usage and update your project settings here. 4. Check your inbox. Click on the Inbox tab to view messages -- receipts of data that was sent to your project inbox. Click on the Inbox tab. 5. Run a job. You should see your first message associated with a \"sample job\". Click on it. You can now choose to do the following: Edit the message (mainly for the purpose of fixing mistakes in data), Manually run the job associated with a filter which has identified your first message as a trigger. See the Current Potential section for all jobs that can be run against this message based on their triggers and the message body. Click run. 6. View the Associated Runs. After running the job, view the run logs in this section below. - Click into a run to see what happened to the data inside of the message. In the logs, you should be able to see the status (success/error) of the run. - Go to the \"Run History\" navigation tab to also view every job run log and its status. 7. Familiarize yourself with the other tabs. Navigate to Triggers . You can see that the sample filter we provided you required a message to be sent from OpenFn in order to trigger a job run. Click on the filter to edit it. Click save when you are done. Navigate to Jobs . Here you can: You can click to view the job that was run when triggered by the sample filter and sample message. Click on \"Edit Job\" to edit the .js file which executes a specific action (job). Click on the specified filter to change which filter should trigger that job. Navigate to Credentials to edit the destination system you want to connect to. By default, we have provided credentials to access the Salesforce sandbox environment. Navigate to the Settings tab to change the project's name, upgrade your account for more jobs and runs, add collaborators, and transfer project ownership. Connecting Source Applications # Most modern web applications have a feature that allows you to push , publish , or post data to another URL when a certain event takes place. This event could be a form submission, mobile payment, patient registration, or barcode scan submission from a mobile app. The key is that your source application will notify OpenFn when something happens . Go to the \"settings\" or \"administration\" page for your source app, and look for a Webhook API , Data Forwarding API , or Notifications API . Write to the developers of your application if none is provided out of the box. When setting up forwarding, select to send messages in JSON to your project's inbox URL . This is a UUID that serves as your API token. You can find and copy your secure inbox URL by clicking on the \"copy URL\" link in the bottom-right corner of the project in question on your project dashboard page or by using the \"Copy URL\" button on your project's \"Inbox\" page.. Soon you'll see new messages arrive in your Inbox . Creating a compatible notifications service # If you are a developer, looking to set up a compatible notifications API for OpenFn, please see our Application Developers section. Triggers # Triggers run jobs. They can either be \"filter\" triggers or \"timer\" triggers. Filter triggers watch incoming messages and run them through jobs when they match the filter criteria. Timer triggers run jobs after a recurring interval has elapsed. You, as a user, specify the filter criteria which determines which messages in your inbox should trigger job runs. This means that if any segment of a message body matches the string of JSON you gave as a filter, the filter will run and trigger a job (assuming you created one). The filter criteria takes the form of a string of valid JSON . In a SQL query, this string will be used in the WHERE clause, for example: 1 2 3 SELECT * FROM receipts WHERE body :: jsonb @ { Name : Aleksa Iwobi } :: jsonb ; Filter Matching # To illustrate filter matching, refer to the JSON strings below. Message \"a\" will match filter '1', but message \"b\" will not. Filter 1: # 1 { formID : patient_registration_v7 } Message a (MATCH): # 1 { submissionDate : 2016-01-15 , formID : patient_registration_v7 , name : Jack Wilshere , dob : 1986-05-16 , medications : [ anaphlene , zaradood , morphofast ]} Message b (NO MATCH): # 1 { submissionDate : 2016-01-16 , formID : patient_registration_v8 , name : Larry Bird , dob : 1982-03-21 , medications : [ anaphlene , zaradood , morphofast ]} Message 'b' does not include \"formID\":\"patient_registration_v7\" and will not match filter '1'. Processing time-triggered jobs # On-demand processing for jobs triggered by timers. If you\u2019re leveraging timer triggers to run jobs at specific time intervals, you can now run a time triggered job on demand. This way you don\u2019t have to wait for the timer to expire before testing! Simply click the process/ \u201cplay\u201d button now available via the Job, Run, and Activity History pages. Credentials # Credentials are used to authorize connections to destination systems. In the future, our adaptors will use credentials to fetch meta-data from source and destination applications and make the job writing process easier. Some systems (Salesforce, OpenMRS, DHIS2) require an instanceUrl, host, or ApiUrl. Leave off the final \"/\" in these Urls: https://login.salesforce.com or http://demo.openmrs.org/openmrs or https://play.dhis2.org . Credentials can only be viewed, or edited by a single user \u2014 their \"owner\" (or the person that created that credential). All the collaborators on a particular project can choose those credentials for use when defining a job. Jobs # A job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed. Composing Job Expressions # In most cases, a job expression is a series of create or upsert actions that are run after a message arrives, using data from that message. It could look like this: Basic Job Expression # 1 2 3 4 create ( Patient__c , fields ( field ( Name , dataValue ( form.surname )), field ( Age__c , 7 ) )); That would create a new Patient__c in some other system. The patient's Name will be determined by the triggering message (the value inside form.surname , specifically) and the patient's Age__c will always be 7. See how we hard coded it? What you see above is OpenFn's own syntax, and you've got access to dozens of common \"helper functions\" like dataValue(path) and destination specific functions like create(object,attributes) . While most cases are covered out-of-the-box, jobs are evaluated as Javascript . This means that you can write your own custom, anonymous functions to do whatever your heart desires: Job Expression with Custom Javascript # 1 2 3 4 5 6 7 create ( Patient__c , fields ( field ( Name , state = { console . log ( Manipulate state to get your desired output. ); return Array . apply ( null , state . data . form . names ). join ( , ); }), field ( Age__c , 7 ) )); Here, the patient's name will be a comma separated concatenation of all the values in the patient_names array from our source message. Available Javascript Globals # For security reasons, users start with access to the following standard Javascript globals, and can request more by opening an issue on Github: Array console JSON Number Promise String *N.B. The runtime environment on the server is Node v6.5.0. Other than the expression tree, Jobs have certain attributes that must be set: Filter - The message filter that will triggers the job. Adaptor - The adaptor for the destination system you're connecting to. Credential - The credential that will be used to gain access to that destination system. Active? - A boolean which determines whether the job runs in real-time when matching messages arrive. Selected Named Functions # There are lots more available in the language-packs. language-common # field('destination_field_name__c', 'value') Returns a key, value pair in an array. (source) fields(list_of_fields) zips key value pairs into an object. (source) dataValue('JSON_path') Picks out a single value from source data. (source) each(JSON_path, operation(...)) Scopes an array of data based on a JSONPath (source) . See beta.each when using multiple each()'s in an expression. each(merge(dataPath(\"CHILD_ARRAY[*]\"),fields(field(\"metaId\", dataValue(\"*meta-instance-id*\")),field(\"parentId\", lastReferenceValue(\"id\")))), create(...)) merges data into an array then creates for each item in the array (source) lastReferenceValue('id') gets the sfID of the last item created (source) function(state){return state.references[state.references.length-N].id}) gets the sfID of the nth item created beta.each(JSON_path, operation(...)) # Scopes an array of data based on a JSONPath but then returns to the state it was given upon completion (source) . This is necessary if you string multiple each(...) functions together in-line in the same expression. (E.g., Given data which has multiple separate 'repeat groups' in a form which are rendered as arrays, you want to create new records for each item inside the first repeat group, then RETURN TO THE TOP LEVEL of the data, and then create new records for each item in the second repeat group. Using beta.each(...) lets you enter the first array, create your records, then return to the top level and be able to enter the second array. Salesforce # create(\"DEST_OBJECT_NAME__C\", fields(...)) Create a new object. Takes 2 parameters: An object and attributes. (source) upsert(\"DEST_OBJECT_NAME__C\", \"DEST_OBJECT_EXTERNAL_ID__C\", fields(...)) Creates or updates an object. Takes 3 paraneters: An object, an ID field and attributes. (source) relationship(\"DEST_RELATIONSHIP_NAME__r\", \"EXTERNAL_ID_ON_RELATED_OBJECT__C\", \"SOURCE_DATA_OR_VALUE\") Adds a lookup or 'dome insert' to a record. (source) dhis2 # event(...) Creates an event. (source) dataValueSet(...) Send data values using the dataValueSets resource (source) OpenMRS # person(...) Takes a payload of data to create a person (source) patient(...) Takes a payload of data to create a patient (source) For code block examples of job expressions, go to the Appendix . Inbox # Your inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data that were sent via HTTP post to your inbox. They can be viewed in formatted JSON, edited, or manually processed (if they did not match a filter when they were originally delivered.) To edit a message, click the \"pencil and paper\" icon next to that receipt. Be careful, as no original copy will be persisted. Filter messages in your inbox # To help you more quickly find relevant messages, you can now filter your inbox by: Body Text - Search your messages for specific text (e.g., find surveys that contain \u201cIndia\u201d in the body). As individual projects may have millions of messages containing tens of thousands of lines of JSON each, we\u2019ve implemented a \u201ctsvector\u201d search strategy. Please be patient and note that this text-based search may take a moment to return results.. If you\u2019re curious about how tsvector works from a technical perspective, check out the official documentation . Date - Choose a relative date range (e.g., \u201cLast 90 Days\u201d) or define a custom date range yourself. Note that the default inbox view shows \u201cLast 30 Days\u201d. Bulk reprocess messages # Need to re-run a series of messages? If you had a job fail because of an error for multiple messages, or need to re-process the data in OpenFn to re-send to a destination application, then this feature will help you do so more quickly! Simply click on the new Reprocess button via the Inbox view. Specify the ID range for messages that you want to re-run (e.g., messages with IDs 4622741 through 4622749 \u2192 9 messages to reprocess). Note when bulk reprocessing messages: This will trigger any jobs that would have run when the given messages first arrived in your OpenFn inbox. In other words, any jobs that are have the autoprocess setting \u201con\u201d will automatically be run if triggered by one of the reprocessed messages. Remember that OpenFn plans are run-based, and you can monitor usage in Project Settings to ensure that you don\u2019t hit any run limits when bulk reprocessing! Export messages to CSV # You can now download and review OpenFn message data by exporting to a CSV file. In your inbox, filter the messages you\u2019d like to export to CSV. Choose to filter by text, date, trigger, and run state. Click the Export as CSV button to generate an export. The link to download this file will be sent to your email address. Activity # In this section of the portal, you can view a list of all \"runs\" - i.e. individual job runs. This list is essentially a compilation of all jobs, messages and credentials flowing through your OpenFn account towards your destination system(s). Runs # Runs are attempts made on a destination system by running a receipt through a Job Description. Runs can be viewed and re-processed. Each submission has a success , started_at , finsihed_at , job_description_id , and receipt_id attribute. Started_at and finished_at are the timestamps when the submission began and ended. Note: Some runs may take a really long time, particularly if they are performing multiple actions in a destination system or if they are fetching lots of data from a REST api at the start of a migration. They will appear as red if they have failed. In the case of failure, refer to our Troubleshooting section below. Filter runs in the Activity view # You can filter the run logs in the Activity View by: Text - Remember to be patient as a full log text search can take time process. Leverage this feature to search for runs with specific error messages to support with troubleshooting any failed runs. Date - Filter the view to only show runs that failed in the last few hours/ days/ year \u2013 or a custom date range! Note that the default activity history view shows runs from the last 30 days. Bulk retry runs # Need to re-process a series of runs? This could be helpful if you had multiple runs fail due to an error message. Simply click on the new Retry button via the Runs view. Specify the ID range for the runs that you want to re-process. Choose to filter by Job and/or Status to only reprocess runs associated with a specific job or runs that have failed/ succeeded. Remember that OpenFn plans are run-based, and you can monitor usage in Project Settings to ensure that you don\u2019t hit any run limits when bulk reprocessing! Export runs to CSV # You can download your run logs by exporting to a CSV file. Via the Runs Activity History view, filter the runs you\u2019d like to export. Choose to filter by text, date, job, and status. Click the Export as CSV button to generate an export. The link to download this file will be sent to your email address. GitHub version control # You're ready to manage your jobs via GitHub, the leading hosted version control software on the web? Great, this section describes the steps necessary to get going. N.B.: GitHub integration is currently only available for enterprise users. Contact enterprise@openfn.org to build a custom plan for your needs. Motivation # Managing large numbers of jobs with multiple contributors is complicated. We developed the GitHub integration so that OpenFn projects can be linked to GitHub repositories. You can work collaboratively on your jobs. When commits are made to a particular branch OpenFn will automatically update the linked job with the new job file from GitHub. Setup Steps # Github: Settings - Personal Access Tokens - Generate New Token : This token should have full control of private repositories. OpenFn: User Settings : Once the token is generated, copy and paste it into the \"GitHub Access Token\" field on your user settings page. OpenFn: Project - Version Control: Specify the repository owner, repository name and branch for automatic deploys. You'd also select to turn on or off automatic deploys. GitHub: Repoistory - Settings - Webhooks - Add webhook Copy Payload URL from OpenFn Version Control page and paste into GitHub. Select application/json as the Content Type. Copy Secret from OpenFn Version Control page into GitHub. Leave \"Just the push event\" and \"Active\" selected, then click \"Add Webook\". OpenFn: Project - Jobs - Job Edit: To link an individual job to a file in a GitHub repo, edit that job and paste in the path to the job from the root of your GitHub repo. If your repo looks like this, you'd type sample_job_1.js or some_folder/some_other_job.js to link your OpenFn job to the select file in your repo. Advanced Version Control # Using this GitHub integration, you can revert to previous version of jobs quickly by resending old GitHub Webhook Events. Access the \"Manage Webhook\" interface on GitHub to see a list of all past events and send whichever version of the job you'd like deployed to your OpenFn project. Troubleshooting # What happens if my survey data from ODK needs to link to existing records in my Salesforce system but a respondent enters or selects an invalid external ID ? Great question, and don't worry, it happens all the time. Assuming you've already taken all possible measures to either pre-load external IDs in your ODK form or use more human-proof IDs (like barcodes and fingerprints) here's the flow of work: Read the email, and inspect the reason for failure. 99% of failed runs on OpenFn are due to value mismatches . The collected id in ODK doesn't match the expected id in Salesforce. You must now chose to either: A. Edit the source id in your receipt retry the attempt. B. Edit the related id in your destination system retry the attempt. C. Ignore the attempt\u2014this source data will never reach your destination system. (There have been reports of ODK Aggregate's JSON publisher sending dupliate values. If that happens and your run fails due to \"duplicate values\" on a particular unique field you can safely ignore the run in OpenFn.) Editing data in your destination system can be done through that system's interface. Many tools that act as sources (like ODK) do not allow for easy editing and re-submission of data. You can use OpenFn to edit the source data before retrying the attempt. Common Error Messages # The most common error messages with English explanations are: DUPLICATE_VALUE: duplicate value found: ODK_uuid__c duplicates value on record with id: a0524000005wNw0 - The insert is blocked because you are attempting to create a new record with a unique field with the same value as an existing record. Required value missing ExternalId not found DIY # OpenFn's core ETL tools are all open-source, and here we will explain how those tools can be used to perform ETL operations from your command line. You can even take this further and wrap them together in your own hosted service! To create an integration service like OpenFn.org, you will need to build a REST endpoint that allows JSON or XML to be posted to it, returning a 2XX and checking the body of that message to see if it matches some criteria. If the criteria match for that message, you must perform execute from fn-lang, using the message data and some stored configuration as state. See a sample state.json below: State.json # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { data : { word_count : 284 , last_update : 2016-11-10 13:58:47 , folder_name : Civil Disobedience , file_owner : student@school.org.za , file_name : Mock Journal Article }, configuration : { host : 109.XXX.11X.2XX , port : 5432 , database : data-warehouse , user : postgres , password : secret-password , ssl : true } } Make sure to store your logs. If you'd like to be able to retry transactions, persist the message data and provide an interface for manipulating that data by hand, or re-running certain transactions after the job expression has been altered. Make sure that a single inbound message can kick off the running of multiple jobs. To get started, or just run fn-lang manually, from your command line, check out openfn-devtools . With windows and linux install scripts, it's the fastest way to get up and running with OpenFn on your local machine. Appendix # Sample code for DIY section # Below you can find sample code to fill the 3 files required to run fn-lang - message.json , expression.js and config.json . message.json # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { xform_ids : [], version : null , user_id : user1 , server_date_opened : null , server_date_modified : null , properties : { prop_c : 2013-05-18 , prop_b : Female , prop_a : 99 , owner_id : null , external_id : null , date_opened : null , date : 2013-05-17 , case_type : case_type , case_name : Demo }, indices : {} } expression.js # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 event ( fields ( field ( program , eBAyeGv0exc ), field ( orgUnit , DiszpKrYNg8 ), field ( eventDate , dataValue ( properties.date )), field ( status , COMPLETED ), field ( storedBy , admin ), field ( coordinate , { latitude : 59.8 , longitude : 10.9 }), field ( dataValues , function ( state ) { return [ { dataElement : qrur9Dvnyt5 , value : dataValue ( properties.prop_a )( state ) }, { dataElement : oZg33kd9taw , value : dataValue ( properties.prop_b )( state ) }, { dataElement : msodh3rEMJa , value : dataValue ( properties.prop_c )( state ) } ] }) ) ) config.json # 1 2 3 4 5 { username : admin , password : district , apiUrl : https://play.dhis2.org/demo } Filters (cont.) # Match messages WHERE the formId is \"Robot_Photo_21.04.2015\" : # 1 { formId : Robot_Photo_21.04.2015 } Match a message WHERE this AND that are both included: # 1 { formId : Robot_Photo_21.04.2015 , secret_number : 8 } Match a message with two fragments inside an array called data : # (This is useful when gathering data via ODK) 1 { data :[{ outlet_call : TRUE , new_existing : Existing }]} Match a message with a fragment inside another object called form : # 1 { form :{ @xmlns : http://openrosa.org/formdesigner/F732194-3278-nota-ReAL-one }} Jobs (cont.) # Below you can find some examples of block code for different functions and data handling contexts. Job expression (for CommCare to SF) # The following job expression will take a matching receipt and use data from that receipt to upsert a Patient__c record in Salesforce and create multiple new Patient_Visit__c (child to Patient) records. 1 2 3 4 5 6 7 8 9 10 11 12 13 upsert ( Patient__c , Patient_Id__c , fields ( field ( Patient_Id__c , dataValue ( form.patient_ID )), relationship ( Nurse__r , Nurse_ID_code__c , dataValue ( form.staff_id )), field ( Phone_Number__c , dataValue ( form.mobile_phone )) )), each ( join ( $.data.form.visits[*] , $.references[0].id , Id ), create ( Visit__c , fields ( field ( Patient__c , dataValue ( Id )), field ( Date__c , dataValue ( date )), field ( Reason__c , dataValue ( why_did_they_see_doctor )) )) ) Accessing the \"data array\" in Open Data Kit submissions # Notice how we use \"each\" to get data from each item inside the \"data array\" in ODK. 1 2 3 4 5 6 7 8 9 each ( $.data.data[*] , create ( ODK_Submission__c , fields ( field ( Site_School_ID_Number__c , dataValue ( school )), field ( Date_Completed__c , dataValue ( date )), field ( comments__c , dataValue ( comments )), field ( ODK_Key__c , dataValue ( *meta-instance-id* )) )) ) ODK to Salesforce: create parent record with many children from parent data # Here, the user brings time_end and parentId onto the line items from the parent object. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 each ( dataPath ( data[*] ), combine ( create ( transaction__c , fields ( field ( Transaction_Date__c , dataValue ( today )), relationship ( Person_Responsible__r , Staff_ID_Code__c , dataValue ( person_code )), field ( metainstanceid__c , dataValue ( *meta-instance-id* )) )), each ( merge ( dataPath ( line_items[*] ), fields ( field ( end , dataValue ( time_end )), field ( parentId , lastReferenceValue ( id )) )), create ( line_item__c , fields ( field ( transaction__c , dataValue ( parentId )), field ( Barcode__c , dataValue ( product_barcode )), field ( ODK_Form_Completed__c , dataValue ( end )) )) ) ) ) NB - there was a known bug with the combine function which has been resolved. combine can be used to combine two operations into one and is commonly used to run multiple create 's inside an each(path, operation) . The source code for combine can be found here: language-common: combine Create many child records WITHOUT a repeat group in ODK # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 beta . each ( $.data.data[*] , upsert ( Outlet__c , Outlet_Code__c , fields ( field ( Outlet_Code__c , dataValue ( outlet_code )), field ( Location__Latitude__s , dataValue ( gps:Latitude )), field ( Location__Longitude__s , dataValue ( gps:Longitude )) )) ), beta . each ( $.data.data[*] , upsert ( Outlet_Call__c , Invoice_Number__c , fields ( field ( Invoice_Number__c , dataValue ( invoice_number )), relationship ( Outlet__r , Outlet_Code__c , dataValue ( outlet_code )), relationship ( RecordType , name , No Call Card ), field ( Trip__c , a0FN0000008jPue ), relationship ( Sales_Person__r , Sales_Rep_Code__c , dataValue ( sales_rep_code )), field ( Date__c , dataValue ( date )), field ( Comments__c , dataValue ( comments )) )) ) Salesforce: perform an update # 1 2 3 4 5 update ( Patient__c , fields ( field ( Id , dataValue ( pathToSalesforceId )), field ( Name__c , dataValue ( patient.first_name )), field (...) )); Salesforce: Set record type using 'relationship(...)' # 1 2 3 4 5 create ( custom_obj__c , fields ( relationship ( RecordType , name , dataValue ( submission_type ), field ( name , dataValue ( Name )) ) )) Salesforce: Set record type using record Type ID # 1 2 3 4 5 6 7 each ( $.data.data[*] , create ( fancy_object__c , fields ( field ( RecordTypeId , 012110000008s19 ), field ( site_size , dataValue ( size )) )) ) Telerivet: Send SMS based on Salesforce workflow alert # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 send ( fields ( field ( to_number , dataValue ( Envelope.Body.notifications.Notification.sObject.phone_number__c )), field ( message_type , sms ), field ( route_id , ), field ( content , function ( state ) { return ( Hey there. Your name is . concat ( dataValue ( Envelope.Body.notifications.Notification.sObject.name__c )( state ), . ) ) }) ) ); HTTP: fetch but don't fail! # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // ============= // We use fetchWithErrors(...) so that when the // SMS gateway returns an error the run does not fail . // It succeeds and then delivers that error message // back to Salesforce with the Update SMS Status job. // ============= fetchWithErrors ({ getEndpoint : send_to_contact , query : function ( state ) { return { msisdn : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Phone_Number__c , message : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Message__c , api_key : some-secret-key } }, externalId : state . data . Envelope . Body . notifications . Notification . sObject . Id , postUrl : https://www.openfn.org/inbox/another-secret-key , }) Sample DHIS2 events API job: # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 event ( fields ( field ( program , eBAyeGv0exc ), field ( orgUnit , DiszpKrYNg8 ), field ( eventDate , dataValue ( properties.date )), field ( status , COMPLETED ), field ( storedBy , admin ), field ( coordinate , { latitude : 59.8 , longitude : 10.9 }), field ( dataValues , function ( state ) { return [ { dataElement : qrur9Dvnyt5 , value : dataValue ( properties.prop_a )( state ) }, { dataElement : oZg33kd9taw , value : dataValue ( properties.prop_b )( state ) }, { dataElement : msodh3rEMJa , value : dataValue ( properties.prop_c )( state ) } ] }) ) ) Sample DHIS2 data value sets API job: # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataValueSet ( fields ( field ( dataSet , pBOMPrpg1QX ), field ( orgUnit , DiszpKrYNg8 ), field ( period , 201401 ), field ( completeData , dataValue ( date )), field ( dataValues , function ( state ) { return [ { dataElement : f7n9E0hX8qk , value : dataValue ( prop_a )( state ) }, { dataElement : Ix2HsbDMLea , value : dataValue ( prop_b )( state ) }, { dataElement : eY5ehpbEsB7 , value : dataValue ( prop_c )( state ) } ] }) ) ) sample openMRS expression, creates a person and then a patient # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 person ( fields ( field ( gender , F ), field ( names , function ( state ) { return [{ givenName : dataValue ( form.first_name )( state ), familyName : dataValue ( form.last_name )( state ) }] }) ) ), patient ( fields ( field ( person , lastReferenceValue ( uuid )), field ( identifiers , function ( state ) { return [{ identifier : 1234 , identifierType : 8d79403a-c2cc-11de-8d13-0010c6dffd0f , location : 8d6c993e-c2cc-11de-8d13-0010c6dffd0f , preferred : true }] }) ) ) merge many values into a child path # 1 2 3 4 5 6 7 8 9 10 each ( merge ( dataPath ( CHILD_ARRAY[*] ), fields ( field ( metaId , dataValue ( *meta-instance-id* )), field ( parentId , lastReferenceValue ( id )) ) ), create (...) ) arrayToString # 1 arrayToString ( arr , separator_string ) access an image URL from an ODK submission # 1 2 // In ODK the image URL is inside an image object... field ( Photo_URL_text__c , dataValue ( image.url )), alterState (alter state) to make sure data is in an array # 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Here, we make sure CommCare gives us an array to use in each(merge(...), ...) alterState (( state ) = { const idCards = state . data . form . ID_cards_given_to_vendor ; if ( ! Array . isArray ( idCards )) { state . data . form . ID_cards_given_to_vendor = [ idCards ]; } return state ; }); // Now state has been changed, and we carry on... each ( merge ( dataPath ( form.ID_cards_given_to_vendor[*] ), fields ( field ( Vendor_Id , dataValue ( form.ID_vendor )), field ( form_finished_time , dataValue ( form.meta.timeEnd )) )), upsert ( Small_Packet__c , sp_id__c , fields ( field ( sp_id__c , dataValue ( ID_cards_given_to_vendor )), relationship ( Vendor__r , Badge_Code__c , dataValue ( Vendor_Id )), field ( Small_Packet_Distribution_Date__c , dataValue ( form_finished_time )) )) ); Anonymous Functions (cont.) # Different to Named Functions , Anoynmous functions are generic pieces of javascript which you can write to suit your needs. Here are some examples of these custom functions: Custom replacer # 1 2 3 4 5 6 field ( destination__c , function ( state ){ return dataValue ( path_to_data )( state ). toString (). replace ( cats , dogs ) } ) This will replace all \"cats\" with \"dogs\" in the string that lives at path_to_data . NOTE: The JavaScript replace() function only replaces the first instance of whatever argument you specify. If you're looking for a way to replace all instances, we suggest you use a regex like we did in the example below. Custom arrayToString # 1 2 3 4 5 field ( target_specie_list__c , function ( state ) { return Array . apply ( null , sourceValue ( $.data.target_specie_list )( state ) ). join ( , ) }), It will take an array, and concatenate each item into a string with a \", \" separator. Custom concatenation # 1 2 3 4 5 6 7 field ( ODK_Key__c , function ( state ) { return ( dataValue ( metaId )( state ). concat ( ( , dataValue ( index )( state ), ) ) ) }) This will concatenate two values. Concatenation of null values # This will concatenate many values, even if one or more are null, writing them to a field called Main_Office_City_c. 1 2 3 4 5 6 7 8 9 ... field ( Main_Office_City__c , function ( state ) { return arrayToString ([ dataValue ( Main_Office_City_a )( state ) === null ? : dataValue ( Main_Office_City_a )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_b )( state ) === null ? : dataValue ( Main_Office_City_b )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_c )( state ) === null ? : dataValue ( Main_Office_City_c )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_d )( state ) === null ? : dataValue ( Main_Office_City_d )( state ). toString (). replace ( /-/g , ), ]. filter ( Boolean ), , ) }) Notice how this custom function makes use of the regex /-/g to ensure that all instances are accounted for (g = global search). Custom Nth reference ID # If you ever want to retrieve the FIRST object you created, or the SECOND, or the Nth, for that matter, a function like this will do the trick. 1 2 3 field ( parent__c , function ( state ) { return state . references [ state . references . length - 1 ]. id }) See how instead of taking the id of the \"last\" thing that was created in Salesforce, you're taking the id of the 1st thing, or 2nd thing if you replace \"length-1\" with \"length-2\". Convert date string to standard ISO date for Salesforce # 1 2 3 field ( Payment_Date__c , function ( state ) { return new Date ( dataValue ( payment_date )( state )). toISOString () }) NOTE : The output of this function will always be formatted according to GMT time-zone. Use external ID fields for relationships during a bulk load in Salesforce # 1 2 3 4 5 6 7 array . map ( item = { return { Patient_Name__c : item . fullName , Clinic__r.Unique_Clinic_Identifier__c : item . clinicId , RecordType.Name : item . type , }; }) Bulk upsert with an external ID in salesforce # 1 2 3 4 5 6 7 8 9 10 bulk ( Visit_new__c , upsert , { extIdField : commcare_case_id__c , failOnError : true , allowNoOp : true , }, dataValue ( patients ) ); Common errors and how to handle them # Are Master-detail relationships in Salesforce reparentable? # 1 2 3 { INVALID_FIELD_FOR_INSERT_UPDATE: Unable to create/update fields: Contact__c. Please check the security settings of this field and verify that it is read/write for your profile or permission set. } This error may arise if a master-detail relationship in Salesforce is not set as reparentable and the user attempts to run an upsert.","title":"Platform Docs"},{"location":"documentation.html#platform-docs","text":"","title":"Platform Docs"},{"location":"documentation.html#quick-start-guide","text":"1. Create your account. If you haven't already, create an account at OpenFn.org 2. Log In. After logging into your new account, you will see an overview of your current projects and the job runs associated with that project. This is called the outer Dashboard . Click on one project to start. 3. Review the navigation bar. You should now be looking at the OpenFn User dashboard for a particular project. Review the following navigation tabs: Jobs | Triggers | Credentials | Inbox | Run History | Version Control | Access Security | Project Settings Jobs. A job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed. Jobs are like the \u201cinstructions\u201d you might give a data entry staff member (e.g., create new Patient record in the database, send SMS with payment confirmation number, etc.). Triggers. A trigger runs jobs based on events, including incoming messages (this is known as a \u201cmessage filter\u201d) or on a timer (a \u201ctime trigger\u201d). Credentials. A credential is used to authorize connection to a destination system (e.g., Salesforce username, password login URL). Inbox. Your inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data (e.g., an incoming SMS, a submitted CommCare form) that were sent via HTTP post to your inbox. Run History. Runs are OpenFn attempts made on a destination system by running a message through a job. Runs can be viewed here and re-processed if there were any errors flagged when running a job. Version Control. Sync your project with a GitHub repository so that every change is tracked using git and jobs can be 'rolled back' to previous commits at the touch of a button. Access Security. - Invite other OpenFn users to collaborate with you on your project and create authentication methods for your project to restrict which applications can send data to your inbox. Settings. Monitor your usage and update your project settings here. 4. Check your inbox. Click on the Inbox tab to view messages -- receipts of data that was sent to your project inbox. Click on the Inbox tab. 5. Run a job. You should see your first message associated with a \"sample job\". Click on it. You can now choose to do the following: Edit the message (mainly for the purpose of fixing mistakes in data), Manually run the job associated with a filter which has identified your first message as a trigger. See the Current Potential section for all jobs that can be run against this message based on their triggers and the message body. Click run. 6. View the Associated Runs. After running the job, view the run logs in this section below. - Click into a run to see what happened to the data inside of the message. In the logs, you should be able to see the status (success/error) of the run. - Go to the \"Run History\" navigation tab to also view every job run log and its status. 7. Familiarize yourself with the other tabs. Navigate to Triggers . You can see that the sample filter we provided you required a message to be sent from OpenFn in order to trigger a job run. Click on the filter to edit it. Click save when you are done. Navigate to Jobs . Here you can: You can click to view the job that was run when triggered by the sample filter and sample message. Click on \"Edit Job\" to edit the .js file which executes a specific action (job). Click on the specified filter to change which filter should trigger that job. Navigate to Credentials to edit the destination system you want to connect to. By default, we have provided credentials to access the Salesforce sandbox environment. Navigate to the Settings tab to change the project's name, upgrade your account for more jobs and runs, add collaborators, and transfer project ownership.","title":"Quick-start guide"},{"location":"documentation.html#connecting-source-applications","text":"Most modern web applications have a feature that allows you to push , publish , or post data to another URL when a certain event takes place. This event could be a form submission, mobile payment, patient registration, or barcode scan submission from a mobile app. The key is that your source application will notify OpenFn when something happens . Go to the \"settings\" or \"administration\" page for your source app, and look for a Webhook API , Data Forwarding API , or Notifications API . Write to the developers of your application if none is provided out of the box. When setting up forwarding, select to send messages in JSON to your project's inbox URL . This is a UUID that serves as your API token. You can find and copy your secure inbox URL by clicking on the \"copy URL\" link in the bottom-right corner of the project in question on your project dashboard page or by using the \"Copy URL\" button on your project's \"Inbox\" page.. Soon you'll see new messages arrive in your Inbox .","title":"Connecting Source Applications"},{"location":"documentation.html#creating-a-compatible-notifications-service","text":"If you are a developer, looking to set up a compatible notifications API for OpenFn, please see our Application Developers section.","title":"Creating a compatible notifications service"},{"location":"documentation.html#triggers","text":"Triggers run jobs. They can either be \"filter\" triggers or \"timer\" triggers. Filter triggers watch incoming messages and run them through jobs when they match the filter criteria. Timer triggers run jobs after a recurring interval has elapsed. You, as a user, specify the filter criteria which determines which messages in your inbox should trigger job runs. This means that if any segment of a message body matches the string of JSON you gave as a filter, the filter will run and trigger a job (assuming you created one). The filter criteria takes the form of a string of valid JSON . In a SQL query, this string will be used in the WHERE clause, for example: 1 2 3 SELECT * FROM receipts WHERE body :: jsonb @ { Name : Aleksa Iwobi } :: jsonb ;","title":"Triggers"},{"location":"documentation.html#filter-matching","text":"To illustrate filter matching, refer to the JSON strings below. Message \"a\" will match filter '1', but message \"b\" will not.","title":"Filter Matching"},{"location":"documentation.html#filter-1","text":"1 { formID : patient_registration_v7 }","title":"Filter 1:"},{"location":"documentation.html#message-a-match","text":"1 { submissionDate : 2016-01-15 , formID : patient_registration_v7 , name : Jack Wilshere , dob : 1986-05-16 , medications : [ anaphlene , zaradood , morphofast ]}","title":"Message a (MATCH):"},{"location":"documentation.html#message-b-no-match","text":"1 { submissionDate : 2016-01-16 , formID : patient_registration_v8 , name : Larry Bird , dob : 1982-03-21 , medications : [ anaphlene , zaradood , morphofast ]} Message 'b' does not include \"formID\":\"patient_registration_v7\" and will not match filter '1'.","title":"Message b (NO MATCH):"},{"location":"documentation.html#processing-time-triggered-jobs","text":"On-demand processing for jobs triggered by timers. If you\u2019re leveraging timer triggers to run jobs at specific time intervals, you can now run a time triggered job on demand. This way you don\u2019t have to wait for the timer to expire before testing! Simply click the process/ \u201cplay\u201d button now available via the Job, Run, and Activity History pages.","title":"Processing time-triggered jobs"},{"location":"documentation.html#credentials","text":"Credentials are used to authorize connections to destination systems. In the future, our adaptors will use credentials to fetch meta-data from source and destination applications and make the job writing process easier. Some systems (Salesforce, OpenMRS, DHIS2) require an instanceUrl, host, or ApiUrl. Leave off the final \"/\" in these Urls: https://login.salesforce.com or http://demo.openmrs.org/openmrs or https://play.dhis2.org . Credentials can only be viewed, or edited by a single user \u2014 their \"owner\" (or the person that created that credential). All the collaborators on a particular project can choose those credentials for use when defining a job.","title":"Credentials"},{"location":"documentation.html#jobs","text":"A job defines the specific series of tasks or database actions to be performed when a triggering message is received or a timer interval has elapsed.","title":"Jobs"},{"location":"documentation.html#composing-job-expressions","text":"In most cases, a job expression is a series of create or upsert actions that are run after a message arrives, using data from that message. It could look like this:","title":"Composing Job Expressions"},{"location":"documentation.html#basic-job-expression","text":"1 2 3 4 create ( Patient__c , fields ( field ( Name , dataValue ( form.surname )), field ( Age__c , 7 ) )); That would create a new Patient__c in some other system. The patient's Name will be determined by the triggering message (the value inside form.surname , specifically) and the patient's Age__c will always be 7. See how we hard coded it? What you see above is OpenFn's own syntax, and you've got access to dozens of common \"helper functions\" like dataValue(path) and destination specific functions like create(object,attributes) . While most cases are covered out-of-the-box, jobs are evaluated as Javascript . This means that you can write your own custom, anonymous functions to do whatever your heart desires:","title":"Basic Job Expression"},{"location":"documentation.html#job-expression-with-custom-javascript","text":"1 2 3 4 5 6 7 create ( Patient__c , fields ( field ( Name , state = { console . log ( Manipulate state to get your desired output. ); return Array . apply ( null , state . data . form . names ). join ( , ); }), field ( Age__c , 7 ) )); Here, the patient's name will be a comma separated concatenation of all the values in the patient_names array from our source message.","title":"Job Expression with Custom Javascript"},{"location":"documentation.html#available-javascript-globals","text":"For security reasons, users start with access to the following standard Javascript globals, and can request more by opening an issue on Github: Array console JSON Number Promise String *N.B. The runtime environment on the server is Node v6.5.0. Other than the expression tree, Jobs have certain attributes that must be set: Filter - The message filter that will triggers the job. Adaptor - The adaptor for the destination system you're connecting to. Credential - The credential that will be used to gain access to that destination system. Active? - A boolean which determines whether the job runs in real-time when matching messages arrive.","title":"Available Javascript Globals"},{"location":"documentation.html#selected-named-functions","text":"There are lots more available in the language-packs.","title":"Selected Named Functions"},{"location":"documentation.html#language-common","text":"field('destination_field_name__c', 'value') Returns a key, value pair in an array. (source) fields(list_of_fields) zips key value pairs into an object. (source) dataValue('JSON_path') Picks out a single value from source data. (source) each(JSON_path, operation(...)) Scopes an array of data based on a JSONPath (source) . See beta.each when using multiple each()'s in an expression. each(merge(dataPath(\"CHILD_ARRAY[*]\"),fields(field(\"metaId\", dataValue(\"*meta-instance-id*\")),field(\"parentId\", lastReferenceValue(\"id\")))), create(...)) merges data into an array then creates for each item in the array (source) lastReferenceValue('id') gets the sfID of the last item created (source) function(state){return state.references[state.references.length-N].id}) gets the sfID of the nth item created","title":"language-common"},{"location":"documentation.html#betaeachjson_path-operation","text":"Scopes an array of data based on a JSONPath but then returns to the state it was given upon completion (source) . This is necessary if you string multiple each(...) functions together in-line in the same expression. (E.g., Given data which has multiple separate 'repeat groups' in a form which are rendered as arrays, you want to create new records for each item inside the first repeat group, then RETURN TO THE TOP LEVEL of the data, and then create new records for each item in the second repeat group. Using beta.each(...) lets you enter the first array, create your records, then return to the top level and be able to enter the second array.","title":"beta.each(JSON_path, operation(...))"},{"location":"documentation.html#salesforce","text":"create(\"DEST_OBJECT_NAME__C\", fields(...)) Create a new object. Takes 2 parameters: An object and attributes. (source) upsert(\"DEST_OBJECT_NAME__C\", \"DEST_OBJECT_EXTERNAL_ID__C\", fields(...)) Creates or updates an object. Takes 3 paraneters: An object, an ID field and attributes. (source) relationship(\"DEST_RELATIONSHIP_NAME__r\", \"EXTERNAL_ID_ON_RELATED_OBJECT__C\", \"SOURCE_DATA_OR_VALUE\") Adds a lookup or 'dome insert' to a record. (source)","title":"Salesforce"},{"location":"documentation.html#dhis2","text":"event(...) Creates an event. (source) dataValueSet(...) Send data values using the dataValueSets resource (source)","title":"dhis2"},{"location":"documentation.html#openmrs","text":"person(...) Takes a payload of data to create a person (source) patient(...) Takes a payload of data to create a patient (source) For code block examples of job expressions, go to the Appendix .","title":"OpenMRS"},{"location":"documentation.html#inbox","text":"Your inbox contains the history of all messages that have passed in to your project, which may or may not have triggered a specific job. Messages are stored payloads or data that were sent via HTTP post to your inbox. They can be viewed in formatted JSON, edited, or manually processed (if they did not match a filter when they were originally delivered.) To edit a message, click the \"pencil and paper\" icon next to that receipt. Be careful, as no original copy will be persisted.","title":"Inbox"},{"location":"documentation.html#filter-messages-in-your-inbox","text":"To help you more quickly find relevant messages, you can now filter your inbox by: Body Text - Search your messages for specific text (e.g., find surveys that contain \u201cIndia\u201d in the body). As individual projects may have millions of messages containing tens of thousands of lines of JSON each, we\u2019ve implemented a \u201ctsvector\u201d search strategy. Please be patient and note that this text-based search may take a moment to return results.. If you\u2019re curious about how tsvector works from a technical perspective, check out the official documentation . Date - Choose a relative date range (e.g., \u201cLast 90 Days\u201d) or define a custom date range yourself. Note that the default inbox view shows \u201cLast 30 Days\u201d.","title":"Filter messages in your inbox"},{"location":"documentation.html#bulk-reprocess-messages","text":"Need to re-run a series of messages? If you had a job fail because of an error for multiple messages, or need to re-process the data in OpenFn to re-send to a destination application, then this feature will help you do so more quickly! Simply click on the new Reprocess button via the Inbox view. Specify the ID range for messages that you want to re-run (e.g., messages with IDs 4622741 through 4622749 \u2192 9 messages to reprocess). Note when bulk reprocessing messages: This will trigger any jobs that would have run when the given messages first arrived in your OpenFn inbox. In other words, any jobs that are have the autoprocess setting \u201con\u201d will automatically be run if triggered by one of the reprocessed messages. Remember that OpenFn plans are run-based, and you can monitor usage in Project Settings to ensure that you don\u2019t hit any run limits when bulk reprocessing!","title":"Bulk reprocess messages"},{"location":"documentation.html#export-messages-to-csv","text":"You can now download and review OpenFn message data by exporting to a CSV file. In your inbox, filter the messages you\u2019d like to export to CSV. Choose to filter by text, date, trigger, and run state. Click the Export as CSV button to generate an export. The link to download this file will be sent to your email address.","title":"Export messages to CSV"},{"location":"documentation.html#activity","text":"In this section of the portal, you can view a list of all \"runs\" - i.e. individual job runs. This list is essentially a compilation of all jobs, messages and credentials flowing through your OpenFn account towards your destination system(s).","title":"Activity"},{"location":"documentation.html#runs","text":"Runs are attempts made on a destination system by running a receipt through a Job Description. Runs can be viewed and re-processed. Each submission has a success , started_at , finsihed_at , job_description_id , and receipt_id attribute. Started_at and finished_at are the timestamps when the submission began and ended. Note: Some runs may take a really long time, particularly if they are performing multiple actions in a destination system or if they are fetching lots of data from a REST api at the start of a migration. They will appear as red if they have failed. In the case of failure, refer to our Troubleshooting section below.","title":"Runs"},{"location":"documentation.html#filter-runs-in-the-activity-view","text":"You can filter the run logs in the Activity View by: Text - Remember to be patient as a full log text search can take time process. Leverage this feature to search for runs with specific error messages to support with troubleshooting any failed runs. Date - Filter the view to only show runs that failed in the last few hours/ days/ year \u2013 or a custom date range! Note that the default activity history view shows runs from the last 30 days.","title":"Filter runs in the Activity view"},{"location":"documentation.html#bulk-retry-runs","text":"Need to re-process a series of runs? This could be helpful if you had multiple runs fail due to an error message. Simply click on the new Retry button via the Runs view. Specify the ID range for the runs that you want to re-process. Choose to filter by Job and/or Status to only reprocess runs associated with a specific job or runs that have failed/ succeeded. Remember that OpenFn plans are run-based, and you can monitor usage in Project Settings to ensure that you don\u2019t hit any run limits when bulk reprocessing!","title":"Bulk retry runs"},{"location":"documentation.html#export-runs-to-csv","text":"You can download your run logs by exporting to a CSV file. Via the Runs Activity History view, filter the runs you\u2019d like to export. Choose to filter by text, date, job, and status. Click the Export as CSV button to generate an export. The link to download this file will be sent to your email address.","title":"Export runs to CSV"},{"location":"documentation.html#github-version-control","text":"You're ready to manage your jobs via GitHub, the leading hosted version control software on the web? Great, this section describes the steps necessary to get going. N.B.: GitHub integration is currently only available for enterprise users. Contact enterprise@openfn.org to build a custom plan for your needs.","title":"GitHub version control"},{"location":"documentation.html#motivation","text":"Managing large numbers of jobs with multiple contributors is complicated. We developed the GitHub integration so that OpenFn projects can be linked to GitHub repositories. You can work collaboratively on your jobs. When commits are made to a particular branch OpenFn will automatically update the linked job with the new job file from GitHub.","title":"Motivation"},{"location":"documentation.html#setup-steps","text":"Github: Settings - Personal Access Tokens - Generate New Token : This token should have full control of private repositories. OpenFn: User Settings : Once the token is generated, copy and paste it into the \"GitHub Access Token\" field on your user settings page. OpenFn: Project - Version Control: Specify the repository owner, repository name and branch for automatic deploys. You'd also select to turn on or off automatic deploys. GitHub: Repoistory - Settings - Webhooks - Add webhook Copy Payload URL from OpenFn Version Control page and paste into GitHub. Select application/json as the Content Type. Copy Secret from OpenFn Version Control page into GitHub. Leave \"Just the push event\" and \"Active\" selected, then click \"Add Webook\". OpenFn: Project - Jobs - Job Edit: To link an individual job to a file in a GitHub repo, edit that job and paste in the path to the job from the root of your GitHub repo. If your repo looks like this, you'd type sample_job_1.js or some_folder/some_other_job.js to link your OpenFn job to the select file in your repo.","title":"Setup Steps"},{"location":"documentation.html#advanced-version-control","text":"Using this GitHub integration, you can revert to previous version of jobs quickly by resending old GitHub Webhook Events. Access the \"Manage Webhook\" interface on GitHub to see a list of all past events and send whichever version of the job you'd like deployed to your OpenFn project.","title":"Advanced Version Control"},{"location":"documentation.html#troubleshooting","text":"What happens if my survey data from ODK needs to link to existing records in my Salesforce system but a respondent enters or selects an invalid external ID ? Great question, and don't worry, it happens all the time. Assuming you've already taken all possible measures to either pre-load external IDs in your ODK form or use more human-proof IDs (like barcodes and fingerprints) here's the flow of work: Read the email, and inspect the reason for failure. 99% of failed runs on OpenFn are due to value mismatches . The collected id in ODK doesn't match the expected id in Salesforce. You must now chose to either: A. Edit the source id in your receipt retry the attempt. B. Edit the related id in your destination system retry the attempt. C. Ignore the attempt\u2014this source data will never reach your destination system. (There have been reports of ODK Aggregate's JSON publisher sending dupliate values. If that happens and your run fails due to \"duplicate values\" on a particular unique field you can safely ignore the run in OpenFn.) Editing data in your destination system can be done through that system's interface. Many tools that act as sources (like ODK) do not allow for easy editing and re-submission of data. You can use OpenFn to edit the source data before retrying the attempt.","title":"Troubleshooting"},{"location":"documentation.html#common-error-messages","text":"The most common error messages with English explanations are: DUPLICATE_VALUE: duplicate value found: ODK_uuid__c duplicates value on record with id: a0524000005wNw0 - The insert is blocked because you are attempting to create a new record with a unique field with the same value as an existing record. Required value missing ExternalId not found","title":"Common Error Messages"},{"location":"documentation.html#diy","text":"OpenFn's core ETL tools are all open-source, and here we will explain how those tools can be used to perform ETL operations from your command line. You can even take this further and wrap them together in your own hosted service! To create an integration service like OpenFn.org, you will need to build a REST endpoint that allows JSON or XML to be posted to it, returning a 2XX and checking the body of that message to see if it matches some criteria. If the criteria match for that message, you must perform execute from fn-lang, using the message data and some stored configuration as state. See a sample state.json below:","title":"DIY"},{"location":"documentation.html#statejson","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { data : { word_count : 284 , last_update : 2016-11-10 13:58:47 , folder_name : Civil Disobedience , file_owner : student@school.org.za , file_name : Mock Journal Article }, configuration : { host : 109.XXX.11X.2XX , port : 5432 , database : data-warehouse , user : postgres , password : secret-password , ssl : true } } Make sure to store your logs. If you'd like to be able to retry transactions, persist the message data and provide an interface for manipulating that data by hand, or re-running certain transactions after the job expression has been altered. Make sure that a single inbound message can kick off the running of multiple jobs. To get started, or just run fn-lang manually, from your command line, check out openfn-devtools . With windows and linux install scripts, it's the fastest way to get up and running with OpenFn on your local machine.","title":"State.json"},{"location":"documentation.html#appendix","text":"","title":"Appendix"},{"location":"documentation.html#sample-code-for-diy-section","text":"Below you can find sample code to fill the 3 files required to run fn-lang - message.json , expression.js and config.json .","title":"Sample code for DIY section"},{"location":"documentation.html#messagejson","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { xform_ids : [], version : null , user_id : user1 , server_date_opened : null , server_date_modified : null , properties : { prop_c : 2013-05-18 , prop_b : Female , prop_a : 99 , owner_id : null , external_id : null , date_opened : null , date : 2013-05-17 , case_type : case_type , case_name : Demo }, indices : {} }","title":"message.json"},{"location":"documentation.html#expressionjs","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 event ( fields ( field ( program , eBAyeGv0exc ), field ( orgUnit , DiszpKrYNg8 ), field ( eventDate , dataValue ( properties.date )), field ( status , COMPLETED ), field ( storedBy , admin ), field ( coordinate , { latitude : 59.8 , longitude : 10.9 }), field ( dataValues , function ( state ) { return [ { dataElement : qrur9Dvnyt5 , value : dataValue ( properties.prop_a )( state ) }, { dataElement : oZg33kd9taw , value : dataValue ( properties.prop_b )( state ) }, { dataElement : msodh3rEMJa , value : dataValue ( properties.prop_c )( state ) } ] }) ) )","title":"expression.js"},{"location":"documentation.html#configjson","text":"1 2 3 4 5 { username : admin , password : district , apiUrl : https://play.dhis2.org/demo }","title":"config.json"},{"location":"documentation.html#filters-cont","text":"","title":"Filters (cont.)"},{"location":"documentation.html#match-messages-where-the-formid-is-robot_photo_21042015","text":"1 { formId : Robot_Photo_21.04.2015 }","title":"Match messages WHERE the formId is \"Robot_Photo_21.04.2015\":"},{"location":"documentation.html#match-a-message-where-this-and-that-are-both-included","text":"1 { formId : Robot_Photo_21.04.2015 , secret_number : 8 }","title":"Match a message WHERE this AND that are both included:"},{"location":"documentation.html#match-a-message-with-two-fragments-inside-an-array-called-data","text":"(This is useful when gathering data via ODK) 1 { data :[{ outlet_call : TRUE , new_existing : Existing }]}","title":"Match a message with two fragments inside an array called data:"},{"location":"documentation.html#match-a-message-with-a-fragment-inside-another-object-called-form","text":"1 { form :{ @xmlns : http://openrosa.org/formdesigner/F732194-3278-nota-ReAL-one }}","title":"Match a message with a fragment inside another object called form:"},{"location":"documentation.html#jobs-cont","text":"Below you can find some examples of block code for different functions and data handling contexts.","title":"Jobs (cont.)"},{"location":"documentation.html#job-expression-for-commcare-to-sf","text":"The following job expression will take a matching receipt and use data from that receipt to upsert a Patient__c record in Salesforce and create multiple new Patient_Visit__c (child to Patient) records. 1 2 3 4 5 6 7 8 9 10 11 12 13 upsert ( Patient__c , Patient_Id__c , fields ( field ( Patient_Id__c , dataValue ( form.patient_ID )), relationship ( Nurse__r , Nurse_ID_code__c , dataValue ( form.staff_id )), field ( Phone_Number__c , dataValue ( form.mobile_phone )) )), each ( join ( $.data.form.visits[*] , $.references[0].id , Id ), create ( Visit__c , fields ( field ( Patient__c , dataValue ( Id )), field ( Date__c , dataValue ( date )), field ( Reason__c , dataValue ( why_did_they_see_doctor )) )) )","title":"Job expression (for CommCare to SF)"},{"location":"documentation.html#accessing-the-data-array-in-open-data-kit-submissions","text":"Notice how we use \"each\" to get data from each item inside the \"data array\" in ODK. 1 2 3 4 5 6 7 8 9 each ( $.data.data[*] , create ( ODK_Submission__c , fields ( field ( Site_School_ID_Number__c , dataValue ( school )), field ( Date_Completed__c , dataValue ( date )), field ( comments__c , dataValue ( comments )), field ( ODK_Key__c , dataValue ( *meta-instance-id* )) )) )","title":"Accessing the \"data array\" in Open Data Kit submissions"},{"location":"documentation.html#odk-to-salesforce-create-parent-record-with-many-children-from-parent-data","text":"Here, the user brings time_end and parentId onto the line items from the parent object. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 each ( dataPath ( data[*] ), combine ( create ( transaction__c , fields ( field ( Transaction_Date__c , dataValue ( today )), relationship ( Person_Responsible__r , Staff_ID_Code__c , dataValue ( person_code )), field ( metainstanceid__c , dataValue ( *meta-instance-id* )) )), each ( merge ( dataPath ( line_items[*] ), fields ( field ( end , dataValue ( time_end )), field ( parentId , lastReferenceValue ( id )) )), create ( line_item__c , fields ( field ( transaction__c , dataValue ( parentId )), field ( Barcode__c , dataValue ( product_barcode )), field ( ODK_Form_Completed__c , dataValue ( end )) )) ) ) ) NB - there was a known bug with the combine function which has been resolved. combine can be used to combine two operations into one and is commonly used to run multiple create 's inside an each(path, operation) . The source code for combine can be found here: language-common: combine","title":"ODK to Salesforce: create parent record with many children from parent data"},{"location":"documentation.html#create-many-child-records-without-a-repeat-group-in-odk","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 beta . each ( $.data.data[*] , upsert ( Outlet__c , Outlet_Code__c , fields ( field ( Outlet_Code__c , dataValue ( outlet_code )), field ( Location__Latitude__s , dataValue ( gps:Latitude )), field ( Location__Longitude__s , dataValue ( gps:Longitude )) )) ), beta . each ( $.data.data[*] , upsert ( Outlet_Call__c , Invoice_Number__c , fields ( field ( Invoice_Number__c , dataValue ( invoice_number )), relationship ( Outlet__r , Outlet_Code__c , dataValue ( outlet_code )), relationship ( RecordType , name , No Call Card ), field ( Trip__c , a0FN0000008jPue ), relationship ( Sales_Person__r , Sales_Rep_Code__c , dataValue ( sales_rep_code )), field ( Date__c , dataValue ( date )), field ( Comments__c , dataValue ( comments )) )) )","title":"Create many child records WITHOUT a repeat group in ODK"},{"location":"documentation.html#salesforce-perform-an-update","text":"1 2 3 4 5 update ( Patient__c , fields ( field ( Id , dataValue ( pathToSalesforceId )), field ( Name__c , dataValue ( patient.first_name )), field (...) ));","title":"Salesforce: perform an update"},{"location":"documentation.html#salesforce-set-record-type-using-relationship","text":"1 2 3 4 5 create ( custom_obj__c , fields ( relationship ( RecordType , name , dataValue ( submission_type ), field ( name , dataValue ( Name )) ) ))","title":"Salesforce: Set record type using 'relationship(...)'"},{"location":"documentation.html#salesforce-set-record-type-using-record-type-id","text":"1 2 3 4 5 6 7 each ( $.data.data[*] , create ( fancy_object__c , fields ( field ( RecordTypeId , 012110000008s19 ), field ( site_size , dataValue ( size )) )) )","title":"Salesforce: Set record type using record Type ID"},{"location":"documentation.html#telerivet-send-sms-based-on-salesforce-workflow-alert","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 send ( fields ( field ( to_number , dataValue ( Envelope.Body.notifications.Notification.sObject.phone_number__c )), field ( message_type , sms ), field ( route_id , ), field ( content , function ( state ) { return ( Hey there. Your name is . concat ( dataValue ( Envelope.Body.notifications.Notification.sObject.name__c )( state ), . ) ) }) ) );","title":"Telerivet: Send SMS based on Salesforce workflow alert"},{"location":"documentation.html#http-fetch-but-dont-fail","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // ============= // We use fetchWithErrors(...) so that when the // SMS gateway returns an error the run does not fail . // It succeeds and then delivers that error message // back to Salesforce with the Update SMS Status job. // ============= fetchWithErrors ({ getEndpoint : send_to_contact , query : function ( state ) { return { msisdn : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Phone_Number__c , message : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Message__c , api_key : some-secret-key } }, externalId : state . data . Envelope . Body . notifications . Notification . sObject . Id , postUrl : https://www.openfn.org/inbox/another-secret-key , })","title":"HTTP: fetch but don't fail!"},{"location":"documentation.html#sample-dhis2-events-api-job","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 event ( fields ( field ( program , eBAyeGv0exc ), field ( orgUnit , DiszpKrYNg8 ), field ( eventDate , dataValue ( properties.date )), field ( status , COMPLETED ), field ( storedBy , admin ), field ( coordinate , { latitude : 59.8 , longitude : 10.9 }), field ( dataValues , function ( state ) { return [ { dataElement : qrur9Dvnyt5 , value : dataValue ( properties.prop_a )( state ) }, { dataElement : oZg33kd9taw , value : dataValue ( properties.prop_b )( state ) }, { dataElement : msodh3rEMJa , value : dataValue ( properties.prop_c )( state ) } ] }) ) )","title":"Sample DHIS2 events API job:"},{"location":"documentation.html#sample-dhis2-data-value-sets-api-job","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 dataValueSet ( fields ( field ( dataSet , pBOMPrpg1QX ), field ( orgUnit , DiszpKrYNg8 ), field ( period , 201401 ), field ( completeData , dataValue ( date )), field ( dataValues , function ( state ) { return [ { dataElement : f7n9E0hX8qk , value : dataValue ( prop_a )( state ) }, { dataElement : Ix2HsbDMLea , value : dataValue ( prop_b )( state ) }, { dataElement : eY5ehpbEsB7 , value : dataValue ( prop_c )( state ) } ] }) ) )","title":"Sample DHIS2 data value sets API job:"},{"location":"documentation.html#sample-openmrs-expression-creates-a-person-and-then-a-patient","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 person ( fields ( field ( gender , F ), field ( names , function ( state ) { return [{ givenName : dataValue ( form.first_name )( state ), familyName : dataValue ( form.last_name )( state ) }] }) ) ), patient ( fields ( field ( person , lastReferenceValue ( uuid )), field ( identifiers , function ( state ) { return [{ identifier : 1234 , identifierType : 8d79403a-c2cc-11de-8d13-0010c6dffd0f , location : 8d6c993e-c2cc-11de-8d13-0010c6dffd0f , preferred : true }] }) ) )","title":"sample openMRS expression, creates a person and then a patient"},{"location":"documentation.html#merge-many-values-into-a-child-path","text":"1 2 3 4 5 6 7 8 9 10 each ( merge ( dataPath ( CHILD_ARRAY[*] ), fields ( field ( metaId , dataValue ( *meta-instance-id* )), field ( parentId , lastReferenceValue ( id )) ) ), create (...) )","title":"merge many values into a child path"},{"location":"documentation.html#arraytostring","text":"1 arrayToString ( arr , separator_string )","title":"arrayToString"},{"location":"documentation.html#access-an-image-url-from-an-odk-submission","text":"1 2 // In ODK the image URL is inside an image object... field ( Photo_URL_text__c , dataValue ( image.url )),","title":"access an image URL from an ODK submission"},{"location":"documentation.html#alterstate-alter-state-to-make-sure-data-is-in-an-array","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Here, we make sure CommCare gives us an array to use in each(merge(...), ...) alterState (( state ) = { const idCards = state . data . form . ID_cards_given_to_vendor ; if ( ! Array . isArray ( idCards )) { state . data . form . ID_cards_given_to_vendor = [ idCards ]; } return state ; }); // Now state has been changed, and we carry on... each ( merge ( dataPath ( form.ID_cards_given_to_vendor[*] ), fields ( field ( Vendor_Id , dataValue ( form.ID_vendor )), field ( form_finished_time , dataValue ( form.meta.timeEnd )) )), upsert ( Small_Packet__c , sp_id__c , fields ( field ( sp_id__c , dataValue ( ID_cards_given_to_vendor )), relationship ( Vendor__r , Badge_Code__c , dataValue ( Vendor_Id )), field ( Small_Packet_Distribution_Date__c , dataValue ( form_finished_time )) )) );","title":"alterState (alter state) to make sure data is in an array"},{"location":"documentation.html#anonymous-functions-cont","text":"Different to Named Functions , Anoynmous functions are generic pieces of javascript which you can write to suit your needs. Here are some examples of these custom functions:","title":"Anonymous Functions (cont.)"},{"location":"documentation.html#custom-replacer","text":"1 2 3 4 5 6 field ( destination__c , function ( state ){ return dataValue ( path_to_data )( state ). toString (). replace ( cats , dogs ) } ) This will replace all \"cats\" with \"dogs\" in the string that lives at path_to_data . NOTE: The JavaScript replace() function only replaces the first instance of whatever argument you specify. If you're looking for a way to replace all instances, we suggest you use a regex like we did in the example below.","title":"Custom replacer"},{"location":"documentation.html#custom-arraytostring","text":"1 2 3 4 5 field ( target_specie_list__c , function ( state ) { return Array . apply ( null , sourceValue ( $.data.target_specie_list )( state ) ). join ( , ) }), It will take an array, and concatenate each item into a string with a \", \" separator.","title":"Custom arrayToString"},{"location":"documentation.html#custom-concatenation","text":"1 2 3 4 5 6 7 field ( ODK_Key__c , function ( state ) { return ( dataValue ( metaId )( state ). concat ( ( , dataValue ( index )( state ), ) ) ) }) This will concatenate two values.","title":"Custom concatenation"},{"location":"documentation.html#concatenation-of-null-values","text":"This will concatenate many values, even if one or more are null, writing them to a field called Main_Office_City_c. 1 2 3 4 5 6 7 8 9 ... field ( Main_Office_City__c , function ( state ) { return arrayToString ([ dataValue ( Main_Office_City_a )( state ) === null ? : dataValue ( Main_Office_City_a )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_b )( state ) === null ? : dataValue ( Main_Office_City_b )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_c )( state ) === null ? : dataValue ( Main_Office_City_c )( state ). toString (). replace ( /-/g , ), dataValue ( Main_Office_City_d )( state ) === null ? : dataValue ( Main_Office_City_d )( state ). toString (). replace ( /-/g , ), ]. filter ( Boolean ), , ) }) Notice how this custom function makes use of the regex /-/g to ensure that all instances are accounted for (g = global search).","title":"Concatenation of null values"},{"location":"documentation.html#custom-nth-reference-id","text":"If you ever want to retrieve the FIRST object you created, or the SECOND, or the Nth, for that matter, a function like this will do the trick. 1 2 3 field ( parent__c , function ( state ) { return state . references [ state . references . length - 1 ]. id }) See how instead of taking the id of the \"last\" thing that was created in Salesforce, you're taking the id of the 1st thing, or 2nd thing if you replace \"length-1\" with \"length-2\".","title":"Custom Nth reference ID"},{"location":"documentation.html#convert-date-string-to-standard-iso-date-for-salesforce","text":"1 2 3 field ( Payment_Date__c , function ( state ) { return new Date ( dataValue ( payment_date )( state )). toISOString () }) NOTE : The output of this function will always be formatted according to GMT time-zone.","title":"Convert date string to standard ISO date for Salesforce"},{"location":"documentation.html#use-external-id-fields-for-relationships-during-a-bulk-load-in-salesforce","text":"1 2 3 4 5 6 7 array . map ( item = { return { Patient_Name__c : item . fullName , Clinic__r.Unique_Clinic_Identifier__c : item . clinicId , RecordType.Name : item . type , }; })","title":"Use external ID fields for relationships during a bulk load in Salesforce"},{"location":"documentation.html#bulk-upsert-with-an-external-id-in-salesforce","text":"1 2 3 4 5 6 7 8 9 10 bulk ( Visit_new__c , upsert , { extIdField : commcare_case_id__c , failOnError : true , allowNoOp : true , }, dataValue ( patients ) );","title":"Bulk upsert with an external ID in salesforce"},{"location":"documentation.html#common-errors-and-how-to-handle-them","text":"","title":"Common errors and how to handle them"},{"location":"documentation.html#are-master-detail-relationships-in-salesforce-reparentable","text":"1 2 3 { INVALID_FIELD_FOR_INSERT_UPDATE: Unable to create/update fields: Contact__c. Please check the security settings of this field and verify that it is read/write for your profile or permission set. } This error may arise if a master-detail relationship in Salesforce is not set as reparentable and the user attempts to run an upsert.","title":"Are Master-detail relationships in Salesforce reparentable?"},{"location":"release-notes.html","text":"Version 1.37.0 (2019-10-21) # New features: Submit ODK Collect forms (or any OpenRosa compliant form) directly to an OpenFn inbox, rather than to ODK Aggregate or some other server before forwarding. Version 1.36.0 (2019-10-01) # New features: Allow messages to be deleted (in accordance with plan retention periods) despite having more recent runs related to them. We set the message to \"null\" for these younger runs, but the run logs will still be available until they're past the retention period. This allows sensitive data in the initial message payload to be purged with the retention period, while less sensitive data in the run logs is still kept. Added more specific exit codes to runs for non-standard exits. Note that exit codes above 2 are very rare. See below for new codes from v1.36.0 onwards. Enhanced Error Codes: 0 : success (run succeeded, e.g. a destination system responded with a 200 ) 1 : error (run failed normally, e.g. a destination system responded with a 4XX , 5XX , or some specialized RequiredFieldMissing error.) 2 : run timed out (runs 100s only supported in enterprise plans) 3 : run could not start due to error (could relate to network traffic, but very rare as an error before the run is started will be retried from Redis with an exponential backoff for a very long time) 4 : run completed but logs could not be saved due to error (could relate to network traffice but very rare as an error after the run completed will be retried from Redis with an exponential backoff for a very long time) 5 : unexpected error during job execution 10 : error in core/cli.js execute Version 1.35.0 (2019-10-01) # New features: Default navigation drawer to open and grouped nav items for easier access Various UI bug-fixes Added new indexes on messages and runs for faster search and filter performance. Enhanced bulk-retry feature for runs Enhanced bulk-reprocess feature for messages Added user-warning when connecting a job to a GitHub filepath: the contents at that filepath will overwrite your current OpenFn job on the next GitHub commit Added historical project usage view Added activity cleaning, as per www.openfn.org/pricing#plans to better comply with data protection regulations and improve UI performance Version 1.22.0 (2019-03-10) # New features: Allow filtering by run status (any, success, failed) for bulk retrying runs in the Run Retry modal. Hovering over a message/run displays the full date-time at which it was received/started as well as the relative time (i.e., how long ago) of that action. Version 1.21.0 (2019-03-09) # New features: Added buttons to the Job, Run, and Activity History pages that allow a user to run a time triggered job on demand so that they don't have to wait for the timer to expire to test. Version 1.20.0 (2019-03-07) # New features: We've been busy, but negligent on release notes. To explain all that's changed we've broken the new features list into multiple sections. Messages the \"Inbox\" view: Filter messages by body text . (Be patient, doing tsvector searching across millions of payloads.) Filter by date. (Default inbox view shows last 30 days.) Export messages as a CSV, based on your currently applied filters. Bulk reprocess messages in a series. All projects on paid plans now have their own job running queues. Partial loading to address inbox view performance issues: messages are loaded first on the inbox view, and then their related \"run states\" are calculated and loaded in a second action. Runs the \"Activity History\" view: Filter runs by log text . (This is a full text search and may take some time.) Filter by date. (Default activity history view shows last 30 days.) Bulk retry runs in a series. (With the ability to limit retries to a certain job.) Export runs as a CSV, based on your currently applied filters. Authentication Security: Require basic auth or token auth to make HTTP requests to a project inbox. Project Settings: View the \"inbox URL\" as text with a click-to-reveal button. Show \"pace\" of estimated usage to determine when a plan upgrade will be necessary. Jobs: Ability to create a job, and a trigger all from the same \"Wizard\" view. Triggers: Ability to create \"success\" and \"failure\" triggers so that jobs can be run based on the success or failure of another job run. Version 1.10.0 (2017-05-04) # New features: GitHub integration now generally available for enterprise users. Self-setup interface completed. Version 1.9.0 (2017-03-07) # New features: View matching messages in the job writing interface when a message filter trigger is selected. \"Tree view\" exposed for job expression viewing. With valid syntax, you're able to see your expression as a syntax tree as we step slowly towards a more point-and-click interface. Version 1.75.0 (2016-12-08) # New features: Hold control while clicking on navigation buttons to open the target in a new window. Filter messages in your inbox by their content by selecting a message-filter trigger. Version 1.7.0 (2016-12-05) # 1.7 is all about user experience! # New features: Material design\u2014more whitespace and cleaner lines. Goto page on inbox and activity tables\u2014save time when processing errors. Change number of items per page on inbox and activity table\u2014care with this one on slow connections! Go to next or previous message or run\u2014makes working through an audit trail easier Change user profile settings without changing password Select syntax style for code editors in user settings\u2014clouds midnight is my new favorite Filter projects, jobs, triggers by name\u2014on the fly for quick navigation Add adaptor logos to credentials list\u2014quick identification Specify connection types on \"Apps\" list\u2014seems there was some confusion about this. I know we're missing plenty of apps that have good APIs. Will consider logging API documentation as well. Shift second top-nav to a collapseable \"side nav\"\u2014better use of screen real-esate. Use 'masonry' packing module for jobs, triggers, credentials, and project settings boxes\u2014more efficient use of space Add material design to this documentation page! Version 1.6.0 (2016-11-24) # New features: Updated payment receipts to include project names. Added update(...) to Salesforce adaptor v0.3.0 Added fetchWithErrors to HTTP adaptor v0.3.1 New Salesforce helper function update(...) : It takes an object and, so long as you're using the \"Id\" only updates. 1 2 3 4 5 update ( Patient__c , fields ( field ( Id , dataValue ( pathToSalesforceId ), field ( Name__c , dataValue ( patient.first_name )), field (...) )) New http helper function fetchWithErrors(...) : This function will perform a get request on an endpoint and return the response to another endpoint, regardless of whether the first GET suceeded or failed. It's currently being used to send message receipt confirmations back to a system of origin that uses OpenFn as an intermediary between it and an SMS gateway. If the SMS message doesn't get delivered because the phone number is invalid, we'd like that information the return all the way to Salesforce, rather than erroring out and staying in OpenFn. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // ============= // We use fetchWithErrors(...) so that when the // SMS gateway returns an error the run does not fail . // It succeeds and then delivers that error message // back to Salesforce with the Update SMS Status job. // ============= fetchWithErrors ({ getEndpoint : send_to_contact , query : function ( state ) { return { msisdn : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Phone_Number__c , message : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Message__c , api_key : some-secret-key , }; }, externalId : state . data . Envelope . Body . notifications . Notification . sObject . Id , postUrl : https://www.openfn.org/inbox/another-secret-key , }); Version 1.5.0 (2016-10-05) # New features: Delete credentials Delete triggers Archive jobs Continual testing from status.openfn.org Delete credentials and triggers: Users can now delete credentials and triggers. Archive jobs: Users can now archive jobs, rendering them inactive. Click \"view archived jobs\" to see and restore old jobs. status.openfn.org : is now live, providing continual testing of key OpenFn services. We run both message-filter-based and timer-trigger-based jobs every five minutes to ensure availability, as well as measuring the round-trip time (in ms) that it takes for a server in a different geographical location to send valid JSON to OpenFn then receive and process the 200 response. (This time will vary according to the location of your servers, but it's important to note that we test the full round trip. Our servers typically send out 200s in about 5-6ms, but you can expect the round trip to complete in closer to 750ms.) Version 1.4.0 (2016-09-26) # New features: Run \"matches\" directly from your inbox view. Always display the latest notification, dismiss to scroll back in time. Login and signup server responses Run \"matches\" from inbox: Users can now run matches in a single click from their inbox, getting notifications that runs have successfully started without having to navigate to the Message Inspector page for a given message. Look for the blue \"play\" button next to each match. Simply click to start running that job with the message in question. Latest notifications: User notifications will now be displayed newest-on-top and when there are multiple stacked notifications users will be... well... notified. Click the small \"x\" to dismiss the latest notification, moving backwards in time until all have been read. Login/signup errors: Until now, invalid login messages and duplicate singup emails had been only displayed in your brower's logs. (That's our fault.) You'll now see a handy \"invalid credentials\" or \"email already registered\" message when trying to log in or sign up. Version 1.3.0 (2016-09-20) # New version of language-salesforce allows users to alterState with a custom function. alterState: documentation Version 1.2.0 (2016-09-15) # Users can now select specific adaptor versions for their jobs. Jobs will \"auto-upgrade\" unless locked to a specific version. Adaptor versions: This means that the code beneath your job, once saved with a specific adaptor version, will never change. This is an important step forward for the whole community, as it enables more rapid progress\u2014especially considering the growing number of outside contributors\u2014without risking introducing instability to existing jobs. Each new version of an adaptor will have release notes introducing the new features or changes to helper functions. To allow easy upgrades, we will still mandate that all new versions are backwards compatible. Version 1.1.0 (2016-08-29) # New features: Users can now run jobs based on timers as well as filters. Users can now view logs for all runs, not just the most recent. Jobs are \"aware\" of their last running state. get(...) and post(...) are now supported using the language-http adaptor, allowing users to make their own HTTP calls in jobs. Timer triggers: On the triggers tab, users can set the trigger type to \"timer\" and input a whole number of seconds for the \"interval\". Any \"active\" jobs associated with this trigger will run periodically after the interval elapses. View logs for all runs: By clicking on an individual run from either the Activity tab or the Message Inspector, users can view the full logs for that run, regardless of whether or not a more recent run took place with the same job and message. Job state: When a job runs based on a timer, not an incoming message, it will preserve it's state for the next run. This feature is commonly used by language packs like language-surveycto, language-odk, and others to create a \"cursor\" to offset or limit database queries. For example, fetchSubmissions(...) in the language-surveycto adaptor takes three arguments: formId , afterDate , and postUrl . The first time this job runs it will only fetch submissions after the afterDate . If any submissions are received, it will take the last submission from the array (by date) and persist it in the job_state as lastSubmissionDate . The next time this job runs, say, 300 seconds (5 minutes) later, it will ignore afterDate and instead fetch submissions after lastSubmissionDate . While this particular helper function is very abstract (it does this one thing well) it's possible to write a job that simply alters the final \"state\" before completing, passing whatever data you'd like from THIS RUN to the NEXT RUN of the job. get(...) and post(...): Have a look at this complex job using language-http. See how it is possible to provide a query and a callback for get while post takes a url and a body object. At the end, the user is setting state.lastSubmissionDate to submissions[submissions.length-1].SubmissionDate . See the functions themselves at language-http . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 get ( forms/data/wide/json/someForm , { query : function ( state ) { return { date : state . lastSubmissionDate || Aug 29, 2016 4:44:26 PM }; }, callback : function ( state ) { // Pick submissions out in order to avoid `post` overwriting `response`. var submissions = state . response . body ; // return submissions return submissions . reduce ( function ( acc , item ) { // tag submissions as part of the someForm form item . formId = someForm ; return acc . then ( post ( https://www.openfn.org/inbox/some-inbox-uuid , { body : item }) ); }, Promise . resolve ( state )) . then ( function ( state ) { if ( submissions . length ) { state . lastSubmissionDate = submissions [ submissions . length - 1 ]. SubmissionDate ; } return state ; }) . then ( function ( state ) { delete state . response ; return state ; }); }, });","title":"Release Notes"},{"location":"release-notes.html#version-1370-2019-10-21","text":"New features: Submit ODK Collect forms (or any OpenRosa compliant form) directly to an OpenFn inbox, rather than to ODK Aggregate or some other server before forwarding.","title":"Version 1.37.0 (2019-10-21)"},{"location":"release-notes.html#version-1360-2019-10-01","text":"New features: Allow messages to be deleted (in accordance with plan retention periods) despite having more recent runs related to them. We set the message to \"null\" for these younger runs, but the run logs will still be available until they're past the retention period. This allows sensitive data in the initial message payload to be purged with the retention period, while less sensitive data in the run logs is still kept. Added more specific exit codes to runs for non-standard exits. Note that exit codes above 2 are very rare. See below for new codes from v1.36.0 onwards. Enhanced Error Codes: 0 : success (run succeeded, e.g. a destination system responded with a 200 ) 1 : error (run failed normally, e.g. a destination system responded with a 4XX , 5XX , or some specialized RequiredFieldMissing error.) 2 : run timed out (runs 100s only supported in enterprise plans) 3 : run could not start due to error (could relate to network traffic, but very rare as an error before the run is started will be retried from Redis with an exponential backoff for a very long time) 4 : run completed but logs could not be saved due to error (could relate to network traffice but very rare as an error after the run completed will be retried from Redis with an exponential backoff for a very long time) 5 : unexpected error during job execution 10 : error in core/cli.js execute","title":"Version 1.36.0 (2019-10-01)"},{"location":"release-notes.html#version-1350-2019-10-01","text":"New features: Default navigation drawer to open and grouped nav items for easier access Various UI bug-fixes Added new indexes on messages and runs for faster search and filter performance. Enhanced bulk-retry feature for runs Enhanced bulk-reprocess feature for messages Added user-warning when connecting a job to a GitHub filepath: the contents at that filepath will overwrite your current OpenFn job on the next GitHub commit Added historical project usage view Added activity cleaning, as per www.openfn.org/pricing#plans to better comply with data protection regulations and improve UI performance","title":"Version 1.35.0 (2019-10-01)"},{"location":"release-notes.html#version-1220-2019-03-10","text":"New features: Allow filtering by run status (any, success, failed) for bulk retrying runs in the Run Retry modal. Hovering over a message/run displays the full date-time at which it was received/started as well as the relative time (i.e., how long ago) of that action.","title":"Version 1.22.0 (2019-03-10)"},{"location":"release-notes.html#version-1210-2019-03-09","text":"New features: Added buttons to the Job, Run, and Activity History pages that allow a user to run a time triggered job on demand so that they don't have to wait for the timer to expire to test.","title":"Version 1.21.0 (2019-03-09)"},{"location":"release-notes.html#version-1200-2019-03-07","text":"New features: We've been busy, but negligent on release notes. To explain all that's changed we've broken the new features list into multiple sections. Messages the \"Inbox\" view: Filter messages by body text . (Be patient, doing tsvector searching across millions of payloads.) Filter by date. (Default inbox view shows last 30 days.) Export messages as a CSV, based on your currently applied filters. Bulk reprocess messages in a series. All projects on paid plans now have their own job running queues. Partial loading to address inbox view performance issues: messages are loaded first on the inbox view, and then their related \"run states\" are calculated and loaded in a second action. Runs the \"Activity History\" view: Filter runs by log text . (This is a full text search and may take some time.) Filter by date. (Default activity history view shows last 30 days.) Bulk retry runs in a series. (With the ability to limit retries to a certain job.) Export runs as a CSV, based on your currently applied filters. Authentication Security: Require basic auth or token auth to make HTTP requests to a project inbox. Project Settings: View the \"inbox URL\" as text with a click-to-reveal button. Show \"pace\" of estimated usage to determine when a plan upgrade will be necessary. Jobs: Ability to create a job, and a trigger all from the same \"Wizard\" view. Triggers: Ability to create \"success\" and \"failure\" triggers so that jobs can be run based on the success or failure of another job run.","title":"Version 1.20.0 (2019-03-07)"},{"location":"release-notes.html#version-1100-2017-05-04","text":"New features: GitHub integration now generally available for enterprise users. Self-setup interface completed.","title":"Version 1.10.0 (2017-05-04)"},{"location":"release-notes.html#version-190-2017-03-07","text":"New features: View matching messages in the job writing interface when a message filter trigger is selected. \"Tree view\" exposed for job expression viewing. With valid syntax, you're able to see your expression as a syntax tree as we step slowly towards a more point-and-click interface.","title":"Version 1.9.0 (2017-03-07)"},{"location":"release-notes.html#version-1750-2016-12-08","text":"New features: Hold control while clicking on navigation buttons to open the target in a new window. Filter messages in your inbox by their content by selecting a message-filter trigger.","title":"Version 1.75.0 (2016-12-08)"},{"location":"release-notes.html#version-170-2016-12-05","text":"","title":"Version 1.7.0 (2016-12-05)"},{"location":"release-notes.html#17-is-all-about-user-experience","text":"New features: Material design\u2014more whitespace and cleaner lines. Goto page on inbox and activity tables\u2014save time when processing errors. Change number of items per page on inbox and activity table\u2014care with this one on slow connections! Go to next or previous message or run\u2014makes working through an audit trail easier Change user profile settings without changing password Select syntax style for code editors in user settings\u2014clouds midnight is my new favorite Filter projects, jobs, triggers by name\u2014on the fly for quick navigation Add adaptor logos to credentials list\u2014quick identification Specify connection types on \"Apps\" list\u2014seems there was some confusion about this. I know we're missing plenty of apps that have good APIs. Will consider logging API documentation as well. Shift second top-nav to a collapseable \"side nav\"\u2014better use of screen real-esate. Use 'masonry' packing module for jobs, triggers, credentials, and project settings boxes\u2014more efficient use of space Add material design to this documentation page!","title":"1.7 is all about user experience!"},{"location":"release-notes.html#version-160-2016-11-24","text":"New features: Updated payment receipts to include project names. Added update(...) to Salesforce adaptor v0.3.0 Added fetchWithErrors to HTTP adaptor v0.3.1 New Salesforce helper function update(...) : It takes an object and, so long as you're using the \"Id\" only updates. 1 2 3 4 5 update ( Patient__c , fields ( field ( Id , dataValue ( pathToSalesforceId ), field ( Name__c , dataValue ( patient.first_name )), field (...) )) New http helper function fetchWithErrors(...) : This function will perform a get request on an endpoint and return the response to another endpoint, regardless of whether the first GET suceeded or failed. It's currently being used to send message receipt confirmations back to a system of origin that uses OpenFn as an intermediary between it and an SMS gateway. If the SMS message doesn't get delivered because the phone number is invalid, we'd like that information the return all the way to Salesforce, rather than erroring out and staying in OpenFn. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // ============= // We use fetchWithErrors(...) so that when the // SMS gateway returns an error the run does not fail . // It succeeds and then delivers that error message // back to Salesforce with the Update SMS Status job. // ============= fetchWithErrors ({ getEndpoint : send_to_contact , query : function ( state ) { return { msisdn : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Phone_Number__c , message : state . data . Envelope . Body . notifications . Notification . sObject . SMS__Message__c , api_key : some-secret-key , }; }, externalId : state . data . Envelope . Body . notifications . Notification . sObject . Id , postUrl : https://www.openfn.org/inbox/another-secret-key , });","title":"Version 1.6.0 (2016-11-24)"},{"location":"release-notes.html#version-150-2016-10-05","text":"New features: Delete credentials Delete triggers Archive jobs Continual testing from status.openfn.org Delete credentials and triggers: Users can now delete credentials and triggers. Archive jobs: Users can now archive jobs, rendering them inactive. Click \"view archived jobs\" to see and restore old jobs. status.openfn.org : is now live, providing continual testing of key OpenFn services. We run both message-filter-based and timer-trigger-based jobs every five minutes to ensure availability, as well as measuring the round-trip time (in ms) that it takes for a server in a different geographical location to send valid JSON to OpenFn then receive and process the 200 response. (This time will vary according to the location of your servers, but it's important to note that we test the full round trip. Our servers typically send out 200s in about 5-6ms, but you can expect the round trip to complete in closer to 750ms.)","title":"Version 1.5.0 (2016-10-05)"},{"location":"release-notes.html#version-140-2016-09-26","text":"New features: Run \"matches\" directly from your inbox view. Always display the latest notification, dismiss to scroll back in time. Login and signup server responses Run \"matches\" from inbox: Users can now run matches in a single click from their inbox, getting notifications that runs have successfully started without having to navigate to the Message Inspector page for a given message. Look for the blue \"play\" button next to each match. Simply click to start running that job with the message in question. Latest notifications: User notifications will now be displayed newest-on-top and when there are multiple stacked notifications users will be... well... notified. Click the small \"x\" to dismiss the latest notification, moving backwards in time until all have been read. Login/signup errors: Until now, invalid login messages and duplicate singup emails had been only displayed in your brower's logs. (That's our fault.) You'll now see a handy \"invalid credentials\" or \"email already registered\" message when trying to log in or sign up.","title":"Version 1.4.0 (2016-09-26)"},{"location":"release-notes.html#version-130-2016-09-20","text":"New version of language-salesforce allows users to alterState with a custom function. alterState: documentation","title":"Version 1.3.0 (2016-09-20)"},{"location":"release-notes.html#version-120-2016-09-15","text":"Users can now select specific adaptor versions for their jobs. Jobs will \"auto-upgrade\" unless locked to a specific version. Adaptor versions: This means that the code beneath your job, once saved with a specific adaptor version, will never change. This is an important step forward for the whole community, as it enables more rapid progress\u2014especially considering the growing number of outside contributors\u2014without risking introducing instability to existing jobs. Each new version of an adaptor will have release notes introducing the new features or changes to helper functions. To allow easy upgrades, we will still mandate that all new versions are backwards compatible.","title":"Version 1.2.0 (2016-09-15)"},{"location":"release-notes.html#version-110-2016-08-29","text":"New features: Users can now run jobs based on timers as well as filters. Users can now view logs for all runs, not just the most recent. Jobs are \"aware\" of their last running state. get(...) and post(...) are now supported using the language-http adaptor, allowing users to make their own HTTP calls in jobs. Timer triggers: On the triggers tab, users can set the trigger type to \"timer\" and input a whole number of seconds for the \"interval\". Any \"active\" jobs associated with this trigger will run periodically after the interval elapses. View logs for all runs: By clicking on an individual run from either the Activity tab or the Message Inspector, users can view the full logs for that run, regardless of whether or not a more recent run took place with the same job and message. Job state: When a job runs based on a timer, not an incoming message, it will preserve it's state for the next run. This feature is commonly used by language packs like language-surveycto, language-odk, and others to create a \"cursor\" to offset or limit database queries. For example, fetchSubmissions(...) in the language-surveycto adaptor takes three arguments: formId , afterDate , and postUrl . The first time this job runs it will only fetch submissions after the afterDate . If any submissions are received, it will take the last submission from the array (by date) and persist it in the job_state as lastSubmissionDate . The next time this job runs, say, 300 seconds (5 minutes) later, it will ignore afterDate and instead fetch submissions after lastSubmissionDate . While this particular helper function is very abstract (it does this one thing well) it's possible to write a job that simply alters the final \"state\" before completing, passing whatever data you'd like from THIS RUN to the NEXT RUN of the job. get(...) and post(...): Have a look at this complex job using language-http. See how it is possible to provide a query and a callback for get while post takes a url and a body object. At the end, the user is setting state.lastSubmissionDate to submissions[submissions.length-1].SubmissionDate . See the functions themselves at language-http . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 get ( forms/data/wide/json/someForm , { query : function ( state ) { return { date : state . lastSubmissionDate || Aug 29, 2016 4:44:26 PM }; }, callback : function ( state ) { // Pick submissions out in order to avoid `post` overwriting `response`. var submissions = state . response . body ; // return submissions return submissions . reduce ( function ( acc , item ) { // tag submissions as part of the someForm form item . formId = someForm ; return acc . then ( post ( https://www.openfn.org/inbox/some-inbox-uuid , { body : item }) ); }, Promise . resolve ( state )) . then ( function ( state ) { if ( submissions . length ) { state . lastSubmissionDate = submissions [ submissions . length - 1 ]. SubmissionDate ; } return state ; }) . then ( function ( state ) { delete state . response ; return state ; }); }, });","title":"Version 1.1.0 (2016-08-29)"},{"location":"source-apps.html","text":"Standard webhook configuration # This section describes how to enable push notifications from selected source applications or how to configure pull jobs to fetch data from those sources. If you don't see yours in the alphabetical list below feel free to add it with a pull request. To connect an application with standard JSON webhooks, copy your inbox URL from the \"Inbox\" page or your \"Project Settings\" screen and use it as the destination URL on your source application. Unless you have specifically configured it on the \"Access Security\" page, no authentication is required. N.B.: This is by no means an exhaustive list. It is merely a list of common sources that external contributors have added. Remember that anything with a REST api or a JSON-based notification service can be used with OpenFn. CommCare HQ # Go to \"Project Settings\". Click \"Data Forwarding\". \"Add a forwarding location\" for Cases, Forms, or both. Specify JSON, using your OpenFn inbox URL as the target. See the CommCare documentation . Create a message-filter trigger like this . Set up a job running on that filter to process CommCare submissions or case updates. Magpi # Magpi is not able to push data to external URLs. In order to fetch data from Magpi, you must run a job on a timer using langugage-magpi : 1 2 3 4 5 6 fetchSurveyData ({ surveyId : 37479 , // the survey id afterDate : 2016-05-31 , // the initial after date // after the first run, OpenFn will only fetch new submissions postUrl : https://www.openfn.org/inbox/secret-5c25-inbox-ba2c-url // the inbox to post form data to. }); Every time this job runs it will only fetch new data, by default. SurveyCTO # SurveyCTO is not able to push data to external URLs. In order to fetch data from SurveyCTO, you must run a job on a using language-surveycto : 1 2 3 4 5 6 fetchSubmissions ( form_id , // the form id Sep 1, 2016 3:56:02 PM , // the initial after date // after the first run, OpenFn will only fetch new submissions https://www.openfn.org/inbox/something-secret // the inbox to post form data to. ) Every time this job runs it will only fetch new data, by default. Open Data Kit (ODK) Collect # To bypass ODK Aggregate and submit forms directly to OpenFn make the following changes in your ODK Collect app. Select General Settings . Select Server Settings . Under Type , select Other . Under URL , enter `https://www.openfn.org Under Submission path , enter /inbox/your-unique-inbox-url (you can copy this from your OpenFn Inbox). Optional: If you have enabled auth methods on your inbox, enter your username and password on this same screen. Note that you cannot load forms from OpenFn. Forms must be loaded directly via ODK's direct method , which allows you to send forms as files via email/Whatsapp. Users can then choose to download the files and save them in the odk/ forms folder on their mobile. Note that if you want to reverse this setup and configure ODK Collect to re-connect to your Aggregate instance again:` Go back to General Settings . Select Server Settings . Under Type , select ODK Aggregate . Under URL , enter Your Aggregate URL Under Submission path , enter /submissions . Enter your ODK Aggregate username and password on this same screen. Open Data Kit (ODK) Aggregate # To new submissions from ODK in real-time, click the \"Form Management\" tab at the top of your Aggregate interface. Click \"Publish\" next to the form you'd like to publish to OpenFn. A dialogue box will open. In the \"Publish To:\" picklist, select Z-ALPHA JSON Server . Choose which data to publish in the \"Data to Publish:\" picklist. You may: \"Upload Existing Data ONLY\" (ideal for migrations of finished data sets), \"Stream New Submission Data ONLY\" (ideal for new projects), or \"BOTH Upload Existing Stream New Submission Data\" (ideal for connecting ongoing projects which are already running). In the \"URL to publish to:\" text box, enter your OpenFn Inbox UUID. (e.g., https://www.openfn.org/inbox/8ad63a29-mUCh-sEcRET-cODes-wOW ) Leave \"Authorization token:\" blank. Leave \"Include Media as:\" set to \"Links(URLs) to Media\". Click \"Publish\" and enter your email address in the dialogue box. Click the \"Published Data\" tab under \"Form Management\" and select your form to view the status of your publisher. You can also now check your OpenFn inbox to see ODK submissions arrive. Kobo Toolbox # To push data from Kobo, users must click the projects icon on their left-side nav bar. It's in the shape of a globe. Once selecting a project, the Project Settings link will appear at the top left side of the screen. Click it to open the Project Settings page. In the bottom left pane of the project settings page, users must paste their inbox URL from OpenFn into the Rest Services Service URL input area and select JSON Post as the Service Name . Click Add Service to start forwarding new Kobo submissions to OpenFn.org. To test to integration, add a submission manually using the enter data in browser button. Head back to your history page at OpenFn to view the newly submitted data and write a new filter and job to map your Kobo data to any destination system on OpenFn. Here's a sample post from Kobo REST service. Note that questions inside groups are prefixed with groupname/ rather than sitting inside a group object like ODK: json { \"meta/instanceID\": \"uuid:19d72997-8316-4e02-8016-4a8ddf6a2aa4\", \"group1/name\": \"twenty\", \"group1/age\": \"19\", \"formhub/uuid\": \"6f5773a110b046cb97e3d71f6c04e7a6\", \"first_q\": \"hello\", \"final_q\": \"why not?\", \"_xform_id_string\": \"groups\", \"_uuid\": \"19d72997-8316-4e02-8016-4a8ddf6a2aa4\", \"_userform_id\": \"taylordowns2000_groups\", \"_tags\": [], \"_submitted_by\": null, \"_submission_time\": \"2016-04-22T06:38:20\", \"_status\": \"submitted_via_web\", \"_notes\": [], \"_id\": 889409, \"_geolocation\": [ null, null ], \"_bamboo_dataset_id\": \"\", \"_attachments\": [] } Ona.io # To pus data from Ona.io, click on the drop-down menu next to a specific form and select Settings . On the left-side menu, select Webhooks . Paste your OpenFn inbox URL into the URL input field. Click \"Add webhook\". Ensure that the webhook is now listed with the JSON tag, indicating that it will forward data as JSON. Check to see that, once a form is submitted, it is forwarded to your OpenFn inbox. Google Forms/Google Sheets # You can send data to OpenFn whenever a new row is added to a Google Sheet, for example when a new submission is made to a Google Form. Below is some sample code you may add to your Google Sheet to make it push data to OpenFn whenever new rows are added. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 function sendToOpenFn ( e ) { var payload = JSON . stringify ( e ); var url = https://www.openfn.org/inbox/your-id-here ; var options = { method : post , contentType : application/json , payload : payload }; var response = UrlFetchApp . fetch ( url , options ); } function isDate ( v ) { if ( Object . prototype . toString . call ( v ) === [object Date] ) { if ( isNaN ( v . getTime ())) { return false ; } else { return true ; } } else { return false ; } } function isNumber ( v ) { if ( Object . prototype . toString . call ( v ) === [object Number] ) { return true ; } else { return false ; } } function getReportData (){ var bookReportData = { formId : bookReport , data : []}; var data = SpreadsheetApp . getActiveSheet (). getDataRange (). getValues (); var pageCount = 0 ; var bookRating = 0 ; for ( i in data ) { if ( isDate ( data [ i ][ 0 ])){ // ignore header line if ( isNumber ( data [ i ][ 3 ])) { pageCount = data [ i ][ 3 ] } if ( isNumber ( data [ i ][ 6 ])) { bookRating = data [ i ][ 6 ] } bookReportData . data . push ( { Timestamp : data [ i ][ 0 ], Title : data [ i ][ 1 ], Author : data [ i ][ 2 ], NumberOfPages : pageCount , Summary : data [ i ][ 4 ], Protagonist : data [ i ][ 5 ], Rating : bookRating , EmailTeacher : data [ i ][ 7 ], EmailStudent : data [ i ][ 8 ], SendStatus : data [ i ][ 9 ] } ); } } // Logger.log(bookReportData); sendToOpenFn ( bookReportData ); } Application Developers # This section is for you if you are hoping to build or extend an existing application that can connect to OpenFn. We follow modern web-standard JSON api guidelines. For your application to a be data provider (or \"source\") for OpenFn integrations, we highly recommend that you create a \"notifications service\" (sometimes called a \"webhooks service\" or \"event-based push API\"). This is preferrable to using a REST api for two reasons: (1) A notifications service will give your clients the ability to set up real-time integrations, and (2) a notifications service is more efficient for both your servers and OpenFn\u2014instead of having requests be made and handled every X seconds, your servers and OpenFn's servers will only work when new data is available. For your appliation to be a consumer (or \"destination\") for OpenFn, you must either have a standard, JSON-based rest API or create a language-package that meets your API specifications. Sending data to OpenFn # To send data to OpenFn, your application must be able to make an HTTPS post to an external URL with a valid JSON object as the post body. See the following example using cURL: 1 2 3 4 5 curl -X POST \\ -H Content-Type: application/json \\ -H Cache-Control: no-cache \\ -d { foo : bar , baz : qux } \\ https://staging.openfn.org/inbox/some-secret-api-key OpenFn will respond with a 200 and an empty JSON object in the event of a successful post. 400s mean that the user's external URL is wrong, and 500s means that there is an application error on OpenFn. While 500s are rare, they could be due to invalid JSON in your POST body. If you cannot notifiy an external URL when some event takes place, you can still integrate with OpenFn if you have a JSON-based REST API. OpenFn users can make HTTP GET requests to your application and perform additional actions based on your response. You should allow either basic or token authentication and responsd to a valid GET with JSON. There is no specific format for your response, as users can parse it any way they'd like, extracting relevant data and then performing other actions\u2014like loading it into a destination system\u2014with that data. See language-http for details on how users make these generic HTTP requests. Receiving data from OpenFn # To make it easy for users to connect to your application, it's highly recommended that you create a language-package with your required authentication and a set of simple, allowable actions nicely abstracted into \"helper functions\". See language-dhis2 for an example of a language-package which creates a simpler interface for a traditional JSON-based REST api. Language packages are written in Javascript and execute in Node. You can convert OpenFn's JSON into XML, or any other format before sending it to your application and you may make use of any node modules you'd like. See language-postgresql for an example of a language package that connects directly to PostgreSQL databases using a popular NPM module called \"pg\". To receive data from OpenFn's generic language-http langauge package, your application must allow either basic, token, or digest authenticated POST, PUT, or GET requests. (Though it is not advisable to create an API that requires GET requests to create or update data.)","title":"Source Apps"},{"location":"source-apps.html#standard-webhook-configuration","text":"This section describes how to enable push notifications from selected source applications or how to configure pull jobs to fetch data from those sources. If you don't see yours in the alphabetical list below feel free to add it with a pull request. To connect an application with standard JSON webhooks, copy your inbox URL from the \"Inbox\" page or your \"Project Settings\" screen and use it as the destination URL on your source application. Unless you have specifically configured it on the \"Access Security\" page, no authentication is required. N.B.: This is by no means an exhaustive list. It is merely a list of common sources that external contributors have added. Remember that anything with a REST api or a JSON-based notification service can be used with OpenFn.","title":"Standard webhook configuration"},{"location":"source-apps.html#commcare-hq","text":"Go to \"Project Settings\". Click \"Data Forwarding\". \"Add a forwarding location\" for Cases, Forms, or both. Specify JSON, using your OpenFn inbox URL as the target. See the CommCare documentation . Create a message-filter trigger like this . Set up a job running on that filter to process CommCare submissions or case updates.","title":"CommCare HQ"},{"location":"source-apps.html#magpi","text":"Magpi is not able to push data to external URLs. In order to fetch data from Magpi, you must run a job on a timer using langugage-magpi : 1 2 3 4 5 6 fetchSurveyData ({ surveyId : 37479 , // the survey id afterDate : 2016-05-31 , // the initial after date // after the first run, OpenFn will only fetch new submissions postUrl : https://www.openfn.org/inbox/secret-5c25-inbox-ba2c-url // the inbox to post form data to. }); Every time this job runs it will only fetch new data, by default.","title":"Magpi"},{"location":"source-apps.html#surveycto","text":"SurveyCTO is not able to push data to external URLs. In order to fetch data from SurveyCTO, you must run a job on a using language-surveycto : 1 2 3 4 5 6 fetchSubmissions ( form_id , // the form id Sep 1, 2016 3:56:02 PM , // the initial after date // after the first run, OpenFn will only fetch new submissions https://www.openfn.org/inbox/something-secret // the inbox to post form data to. ) Every time this job runs it will only fetch new data, by default.","title":"SurveyCTO"},{"location":"source-apps.html#open-data-kit-odk-collect","text":"To bypass ODK Aggregate and submit forms directly to OpenFn make the following changes in your ODK Collect app. Select General Settings . Select Server Settings . Under Type , select Other . Under URL , enter `https://www.openfn.org Under Submission path , enter /inbox/your-unique-inbox-url (you can copy this from your OpenFn Inbox). Optional: If you have enabled auth methods on your inbox, enter your username and password on this same screen. Note that you cannot load forms from OpenFn. Forms must be loaded directly via ODK's direct method , which allows you to send forms as files via email/Whatsapp. Users can then choose to download the files and save them in the odk/ forms folder on their mobile. Note that if you want to reverse this setup and configure ODK Collect to re-connect to your Aggregate instance again:` Go back to General Settings . Select Server Settings . Under Type , select ODK Aggregate . Under URL , enter Your Aggregate URL Under Submission path , enter /submissions . Enter your ODK Aggregate username and password on this same screen.","title":"Open Data Kit (ODK) Collect"},{"location":"source-apps.html#open-data-kit-odk-aggregate","text":"To new submissions from ODK in real-time, click the \"Form Management\" tab at the top of your Aggregate interface. Click \"Publish\" next to the form you'd like to publish to OpenFn. A dialogue box will open. In the \"Publish To:\" picklist, select Z-ALPHA JSON Server . Choose which data to publish in the \"Data to Publish:\" picklist. You may: \"Upload Existing Data ONLY\" (ideal for migrations of finished data sets), \"Stream New Submission Data ONLY\" (ideal for new projects), or \"BOTH Upload Existing Stream New Submission Data\" (ideal for connecting ongoing projects which are already running). In the \"URL to publish to:\" text box, enter your OpenFn Inbox UUID. (e.g., https://www.openfn.org/inbox/8ad63a29-mUCh-sEcRET-cODes-wOW ) Leave \"Authorization token:\" blank. Leave \"Include Media as:\" set to \"Links(URLs) to Media\". Click \"Publish\" and enter your email address in the dialogue box. Click the \"Published Data\" tab under \"Form Management\" and select your form to view the status of your publisher. You can also now check your OpenFn inbox to see ODK submissions arrive.","title":"Open Data Kit (ODK) Aggregate"},{"location":"source-apps.html#kobo-toolbox","text":"To push data from Kobo, users must click the projects icon on their left-side nav bar. It's in the shape of a globe. Once selecting a project, the Project Settings link will appear at the top left side of the screen. Click it to open the Project Settings page. In the bottom left pane of the project settings page, users must paste their inbox URL from OpenFn into the Rest Services Service URL input area and select JSON Post as the Service Name . Click Add Service to start forwarding new Kobo submissions to OpenFn.org. To test to integration, add a submission manually using the enter data in browser button. Head back to your history page at OpenFn to view the newly submitted data and write a new filter and job to map your Kobo data to any destination system on OpenFn. Here's a sample post from Kobo REST service. Note that questions inside groups are prefixed with groupname/ rather than sitting inside a group object like ODK: json { \"meta/instanceID\": \"uuid:19d72997-8316-4e02-8016-4a8ddf6a2aa4\", \"group1/name\": \"twenty\", \"group1/age\": \"19\", \"formhub/uuid\": \"6f5773a110b046cb97e3d71f6c04e7a6\", \"first_q\": \"hello\", \"final_q\": \"why not?\", \"_xform_id_string\": \"groups\", \"_uuid\": \"19d72997-8316-4e02-8016-4a8ddf6a2aa4\", \"_userform_id\": \"taylordowns2000_groups\", \"_tags\": [], \"_submitted_by\": null, \"_submission_time\": \"2016-04-22T06:38:20\", \"_status\": \"submitted_via_web\", \"_notes\": [], \"_id\": 889409, \"_geolocation\": [ null, null ], \"_bamboo_dataset_id\": \"\", \"_attachments\": [] }","title":"Kobo Toolbox"},{"location":"source-apps.html#onaio","text":"To pus data from Ona.io, click on the drop-down menu next to a specific form and select Settings . On the left-side menu, select Webhooks . Paste your OpenFn inbox URL into the URL input field. Click \"Add webhook\". Ensure that the webhook is now listed with the JSON tag, indicating that it will forward data as JSON. Check to see that, once a form is submitted, it is forwarded to your OpenFn inbox.","title":"Ona.io"},{"location":"source-apps.html#google-formsgoogle-sheets","text":"You can send data to OpenFn whenever a new row is added to a Google Sheet, for example when a new submission is made to a Google Form. Below is some sample code you may add to your Google Sheet to make it push data to OpenFn whenever new rows are added. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 function sendToOpenFn ( e ) { var payload = JSON . stringify ( e ); var url = https://www.openfn.org/inbox/your-id-here ; var options = { method : post , contentType : application/json , payload : payload }; var response = UrlFetchApp . fetch ( url , options ); } function isDate ( v ) { if ( Object . prototype . toString . call ( v ) === [object Date] ) { if ( isNaN ( v . getTime ())) { return false ; } else { return true ; } } else { return false ; } } function isNumber ( v ) { if ( Object . prototype . toString . call ( v ) === [object Number] ) { return true ; } else { return false ; } } function getReportData (){ var bookReportData = { formId : bookReport , data : []}; var data = SpreadsheetApp . getActiveSheet (). getDataRange (). getValues (); var pageCount = 0 ; var bookRating = 0 ; for ( i in data ) { if ( isDate ( data [ i ][ 0 ])){ // ignore header line if ( isNumber ( data [ i ][ 3 ])) { pageCount = data [ i ][ 3 ] } if ( isNumber ( data [ i ][ 6 ])) { bookRating = data [ i ][ 6 ] } bookReportData . data . push ( { Timestamp : data [ i ][ 0 ], Title : data [ i ][ 1 ], Author : data [ i ][ 2 ], NumberOfPages : pageCount , Summary : data [ i ][ 4 ], Protagonist : data [ i ][ 5 ], Rating : bookRating , EmailTeacher : data [ i ][ 7 ], EmailStudent : data [ i ][ 8 ], SendStatus : data [ i ][ 9 ] } ); } } // Logger.log(bookReportData); sendToOpenFn ( bookReportData ); }","title":"Google Forms/Google Sheets"},{"location":"source-apps.html#application-developers","text":"This section is for you if you are hoping to build or extend an existing application that can connect to OpenFn. We follow modern web-standard JSON api guidelines. For your application to a be data provider (or \"source\") for OpenFn integrations, we highly recommend that you create a \"notifications service\" (sometimes called a \"webhooks service\" or \"event-based push API\"). This is preferrable to using a REST api for two reasons: (1) A notifications service will give your clients the ability to set up real-time integrations, and (2) a notifications service is more efficient for both your servers and OpenFn\u2014instead of having requests be made and handled every X seconds, your servers and OpenFn's servers will only work when new data is available. For your appliation to be a consumer (or \"destination\") for OpenFn, you must either have a standard, JSON-based rest API or create a language-package that meets your API specifications.","title":"Application Developers"},{"location":"source-apps.html#sending-data-to-openfn","text":"To send data to OpenFn, your application must be able to make an HTTPS post to an external URL with a valid JSON object as the post body. See the following example using cURL: 1 2 3 4 5 curl -X POST \\ -H Content-Type: application/json \\ -H Cache-Control: no-cache \\ -d { foo : bar , baz : qux } \\ https://staging.openfn.org/inbox/some-secret-api-key OpenFn will respond with a 200 and an empty JSON object in the event of a successful post. 400s mean that the user's external URL is wrong, and 500s means that there is an application error on OpenFn. While 500s are rare, they could be due to invalid JSON in your POST body. If you cannot notifiy an external URL when some event takes place, you can still integrate with OpenFn if you have a JSON-based REST API. OpenFn users can make HTTP GET requests to your application and perform additional actions based on your response. You should allow either basic or token authentication and responsd to a valid GET with JSON. There is no specific format for your response, as users can parse it any way they'd like, extracting relevant data and then performing other actions\u2014like loading it into a destination system\u2014with that data. See language-http for details on how users make these generic HTTP requests.","title":"Sending data to OpenFn"},{"location":"source-apps.html#receiving-data-from-openfn","text":"To make it easy for users to connect to your application, it's highly recommended that you create a language-package with your required authentication and a set of simple, allowable actions nicely abstracted into \"helper functions\". See language-dhis2 for an example of a language-package which creates a simpler interface for a traditional JSON-based REST api. Language packages are written in Javascript and execute in Node. You can convert OpenFn's JSON into XML, or any other format before sending it to your application and you may make use of any node modules you'd like. See language-postgresql for an example of a language package that connects directly to PostgreSQL databases using a popular NPM module called \"pg\". To receive data from OpenFn's generic language-http langauge package, your application must allow either basic, token, or digest authenticated POST, PUT, or GET requests. (Though it is not advisable to create an API that requires GET requests to create or update data.)","title":"Receiving data from OpenFn"}]}